[{
  "history_id" : "ef136vjygcj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675864018527,
  "history_end_time" : 1675864018527,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "z4nr70",
  "indicator" : "Skipped"
},{
  "history_id" : "yyc6mowaayt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675862265365,
  "history_end_time" : 1675862406136,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "z4nr70",
  "indicator" : "Stopped"
},{
  "history_id" : "ldghla7qudt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675862205173,
  "history_end_time" : 1675862231657,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "z4nr70",
  "indicator" : "Stopped"
},{
  "history_id" : "ldzgjwt164s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675862060755,
  "history_end_time" : 1675862183938,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "z4nr70",
  "indicator" : "Stopped"
},{
  "history_id" : "hl7rjauheyq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675861998690,
  "history_end_time" : 1675861998690,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0e25vd5837v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675861962638,
  "history_end_time" : 1675861962638,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xdq1s5mqnu3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675861945262,
  "history_end_time" : 1675861945262,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "nosqlh0d8z7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675776193865,
  "history_end_time" : 1675776193865,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gix61jipxpg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1675171644344,
  "history_end_time" : 1675172362304,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "yl2i3sv32u6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510590,
  "history_end_time" : 1674566510590,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "2e4hbl5dgas",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566390578,
  "history_end_time" : 1674566390578,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "e4o41xbfder",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412904,
  "history_end_time" : 1670331412904,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "71qzurz7mpv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1669994030469,
  "history_end_time" : 1669994030469,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "80vdufyorc8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1669729025923,
  "history_end_time" : 1669729253103,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "68xmj4jdcu3",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1669728693329,
  "history_end_time" : 1669728794588,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wh82axw3r81",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1669125565646,
  "history_end_time" : 1669125632310,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "or5l8bbz653",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1669035208186,
  "history_end_time" : 1669035208186,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "viebtmdpn7y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668659941275,
  "history_end_time" : 1668659941275,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "y81whmyf7xm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668659552206,
  "history_end_time" : 1668659937658,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "yt877ioy3cn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668657107161,
  "history_end_time" : 1668659548554,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "y9a4tg8ongw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668628447179,
  "history_end_time" : 1668628447179,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "wxohnx8mn3n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668624225173,
  "history_end_time" : 1668624225173,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "7g26xptf70r",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668623875370,
  "history_end_time" : 1668623875370,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "vhfy64yemrb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668623442816,
  "history_end_time" : 1668623442816,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rxlenylki16",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668623284841,
  "history_end_time" : 1668623428598,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "b2u8aqkkmyw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668623195086,
  "history_end_time" : 1668623195086,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "m3ct6x46vss",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668623059667,
  "history_end_time" : 1668623191191,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "km6fsy84yzm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668622991338,
  "history_end_time" : 1668623057321,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wc2nfnhl0aj",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668622934233,
  "history_end_time" : 1668622988822,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "iwg35o6mcmq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668621793525,
  "history_end_time" : 1668621793525,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "r3iwnwuggeg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668620779649,
  "history_end_time" : 1668621623246,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "i8h4g3oxlrq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668619675929,
  "history_end_time" : 1668620774902,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gs3kuafwh9c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668619500770,
  "history_end_time" : 1668619500770,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1jepxkht2wx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668619487865,
  "history_end_time" : 1668619496004,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "jd2ucph32mn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668619430773,
  "history_end_time" : 1668619430773,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gnp3xqmbl0c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668618475716,
  "history_end_time" : 1668619427438,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "1nwkxr0z2o0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668617176514,
  "history_end_time" : 1668617179381,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "u6w8tbzibwg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668614586849,
  "history_end_time" : 1668614586849,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "jbi73atjz9o",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668613041894,
  "history_end_time" : 1668613059648,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "29s2w4md8fw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668606689768,
  "history_end_time" : 1668611987872,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "uua7h7c38b5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1668602171287,
  "history_end_time" : 1668606680265,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "7vcw9sgb9j2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667848843005,
  "history_end_time" : 1667848843005,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4v3bg8r0rcu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667848672176,
  "history_end_time" : 1667848802738,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "4bjiglm5qqb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667835946256,
  "history_end_time" : 1667835946256,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1c7ygyjin68",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667834754447,
  "history_end_time" : 1667834755691,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "1q98krn7c2b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667833562717,
  "history_end_time" : 1667834752790,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "0bc7qt5iayf",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667656271482,
  "history_end_time" : 1667656271482,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "s2l1wqyy41q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667654259231,
  "history_end_time" : 1667656266960,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "cv2scsdbwe6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667652444802,
  "history_end_time" : 1667652444802,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "k2c4ymmsyz8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667578123232,
  "history_end_time" : 1667578123232,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1bexzoe8p6p",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667567849396,
  "history_end_time" : 1667578113303,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "br0s7pej7i0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667567845436,
  "history_end_time" : 1667567845436,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ebq19vtdb6m",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667566836949,
  "history_end_time" : 1667567844467,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "6xitgmu53ow",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667566406646,
  "history_end_time" : 1667566406646,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "sgvf3tb7d1h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667564943828,
  "history_end_time" : 1667566400543,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "0iq3xrsklc7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667524735915,
  "history_end_time" : 1667562870445,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "pnhuflex9us",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667188267830,
  "history_end_time" : 1667188267830,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "9pbqftq6pkb",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667187373666,
  "history_end_time" : 1667188257036,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "fhn1w136deq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667187034120,
  "history_end_time" : 1667187364180,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "adutfp6s9y1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667186333403,
  "history_end_time" : 1667186333403,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mx4nedqfv8y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667186213061,
  "history_end_time" : 1667186314345,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "n0cj0goessz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667186212834,
  "history_end_time" : 1667186212834,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xyw09cqhkzx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667185556591,
  "history_end_time" : 1667186204432,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "o8qbzy2n0c2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667185421095,
  "history_end_time" : 1667185421095,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8tc072bvnyo",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667185410500,
  "history_end_time" : 1667185419416,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "tpiaaft0f81",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667184378580,
  "history_end_time" : 1667185392922,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gehf9esqb0w",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667184365798,
  "history_end_time" : 1667184373443,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "wv6ywhunai7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667184279360,
  "history_end_time" : 1667184298771,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "5rkzlbnjp4v",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667184189669,
  "history_end_time" : 1667184270209,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "l9sx7r59ubs",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667180717086,
  "history_end_time" : 1667180717086,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qt5mce8flj5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667180445941,
  "history_end_time" : 1667180628902,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "rwryyve3me8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667180388552,
  "history_end_time" : 1667180438864,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "6ifjk0eyplu",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667180305884,
  "history_end_time" : 1667180359942,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "tov0gw4lhgx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667180257737,
  "history_end_time" : 1667180257737,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8qvx9cqohku",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667091246106,
  "history_end_time" : 1667091390345,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "vt8orr566o8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667085498596,
  "history_end_time" : 1667091234840,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "4dq2bx128qy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666715954465,
  "history_end_time" : 1666715960611,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "6xhu77zzhjc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666715918517,
  "history_end_time" : 1666715941360,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gncsflq9czp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666205807229,
  "history_end_time" : 1666205807229,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "p6waglqp0vz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666205806288,
  "history_end_time" : 1666205806288,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "64d4ryscmkg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666203643237,
  "history_end_time" : 1666203643237,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "1q64463qymq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666203441985,
  "history_end_time" : 1666203441985,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "pkd6o856zvq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666203334992,
  "history_end_time" : 1666203334992,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "opj1fasjjio",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666203334043,
  "history_end_time" : 1666203334043,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "x59bfn334lg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666203001466,
  "history_end_time" : 1666203001466,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qcpct9u22qe",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666202962823,
  "history_end_time" : 1666202962823,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "y4svuc2romm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1666202865172,
  "history_end_time" : 1666202865172,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qmxjje8bhqo",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1665754740299,
  "history_end_time" : 1665757923172,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "9is5wusd6gz",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/9is5wusd6gz/train_test_subsets.py\", line 3, in <module>\n    import torch\nModuleNotFoundError: No module named 'torch'\n",
  "history_begin_time" : 1665096318187,
  "history_end_time" : 1665096318447,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "c32g1bsxazg",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/c32g1bsxazg/train_test_subsets.py\", line 3, in <module>\n    import torch\nModuleNotFoundError: No module named 'torch'\n",
  "history_begin_time" : 1665015431858,
  "history_end_time" : 1665015432104,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "j5nuu4tfz8k",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/j5nuu4tfz8k/train_test_subsets.py\", line 3, in <module>\n    import torch\nModuleNotFoundError: No module named 'torch'\n",
  "history_begin_time" : 1664976220117,
  "history_end_time" : 1664976220293,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "8ucaetorqu4",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/8ucaetorqu4/train_test_subsets.py\", line 3, in <module>\n    import torch\nModuleNotFoundError: No module named 'torch'\n",
  "history_begin_time" : 1664976119400,
  "history_end_time" : 1664976119590,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "lztbce37ql9",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664371772495,
  "history_end_time" : 1664371785535,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jus2ggch08d",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "Cannot run program \"python3.8\" (in directory \"C:\\Users\\user\\gw-workspace\\jus2ggch08d\"): CreateProcess error=2, The system cannot find the file specified",
  "history_begin_time" : 1664371273434,
  "history_end_time" : 1664371273653,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "1dgnnuwkm0s",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664371109389,
  "history_end_time" : 1664371119579,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "8u2ntcjsb9i",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664370678859,
  "history_end_time" : 1664370681704,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6ygedg98uhs",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664327023118,
  "history_end_time" : 1664327028562,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3nl7rsf760k",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664326948165,
  "history_end_time" : 1664326956699,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "f8r5chn4nyk",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664326410106,
  "history_end_time" : 1664326419306,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hsf144t2rx3",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664326220059,
  "history_end_time" : 1664326233831,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "c8j3i9x9nhz",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664324847439,
  "history_end_time" : 1664324860123,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "frqorw5l4c3",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664324745482,
  "history_end_time" : 1664324752294,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "m19brcywefe",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664324705772,
  "history_end_time" : 1664324713182,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0vnk3fjvt5o",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664324378645,
  "history_end_time" : 1664324388012,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "rj326iwp6as",
  "history_input" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1664309493790,
  "history_end_time" : 1664309505416,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "kk433l31cem",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\nfrom subset_arrays import *\nfrom importing_logger import *\nfrom eddy_plots import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "We assume pixel position of grid is centered for C:\\Users\\user\\ML_eddies\\cds_ssh_2019_10day_interval\\dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 987 files for 1998-2018.\nTraceback (most recent call last):\n  File \"train_test_subsets.py\", line 4, in <module>\n    from importing_logger import *\n  File \"C:\\Users\\user\\gw-workspace\\kk433l31cem\\importing_logger.py\", line 17, in <module>\n    train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n  File \"C:\\Users\\user\\gw-workspace\\kk433l31cem\\importing_multiprocessor.py\", line 25, in generate_masks_in_parallel\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\nNameError: name 'generate_segmentation_mask_from_file' is not defined\n",
  "history_begin_time" : 1664309104481,
  "history_end_time" : 1664309123236,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "9fcw4idd47o",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\nfrom subset_arrays import *\nfrom importing_logger import *\nfrom eddy_plots import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "We assume pixel position of grid is centered for C:\\Users\\user\\ML_eddies\\cds_ssh_2019_10day_interval\\dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 987 files for 1998-2018.\nTraceback (most recent call last):\n  File \"train_test_subsets.py\", line 4, in <module>\n    from importing_logger import *\n  File \"C:\\Users\\user\\gw-workspace\\9fcw4idd47o\\importing_logger.py\", line 17, in <module>\n    train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n  File \"C:\\Users\\user\\gw-workspace\\9fcw4idd47o\\importing_multiprocessor.py\", line 25, in generate_masks_in_parallel\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\nNameError: name 'generate_segmentation_mask_from_file' is not defined\n",
  "history_begin_time" : 1664304919844,
  "history_end_time" : 1664304939467,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "lmm6j35kgju",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\nfrom subset_arrays import *\nfrom importing_logger import *\nfrom eddy_plots import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "We assume pixel position of grid is centered for C:\\Users\\user\\ML_eddies\\cds_ssh_2019_10day_interval\\dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 987 files for 1998-2018.\nTraceback (most recent call last):\n  File \"train_test_subsets.py\", line 4, in <module>\n    from importing_logger import *\n  File \"C:\\Users\\user\\gw-workspace\\lmm6j35kgju\\importing_logger.py\", line 17, in <module>\n    train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n  File \"C:\\Users\\user\\gw-workspace\\lmm6j35kgju\\importing_multiprocessor.py\", line 25, in generate_masks_in_parallel\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\nNameError: name 'generate_segmentation_mask_from_file' is not defined\n",
  "history_begin_time" : 1664279673826,
  "history_end_time" : 1664279693937,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "z6smbkatshg",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\nfrom subset_arrays import *\nfrom importing_logger import *\nfrom eddy_plots import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "We assume pixel position of grid is centered for C:\\Users\\user\\ML_eddies\\cds_ssh_2019_10day_interval\\dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 987 files for 1998-2018.\nTraceback (most recent call last):\n  File \"train_test_subsets.py\", line 4, in <module>\n    from importing_logger import *\n  File \"C:\\Users\\user\\gw-workspace\\z6smbkatshg\\importing_logger.py\", line 17, in <module>\n    train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n  File \"C:\\Users\\user\\gw-workspace\\z6smbkatshg\\importing_multiprocessor.py\", line 25, in generate_masks_in_parallel\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\nNameError: name 'generate_segmentation_mask_from_file' is not defined\n",
  "history_begin_time" : 1664279557008,
  "history_end_time" : 1664279574651,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "KjR8z9Omiyus",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\nfrom subset_arrays import *\nfrom importing_logger import *\nfrom eddy_plots import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "We assume pixel position of grid is centered for C:\\Users\\user\\ML_eddies\\cds_ssh_2019_10day_interval\\dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 987 files for 1998-2018.\nTraceback (most recent call last):\n  File \"train_test_subsets.py\", line 4, in <module>\n    from importing_logger import *\n  File \"C:\\Users\\user\\gw-workspace\\KjR8z9Omiyus\\importing_logger.py\", line 17, in <module>\n    train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n  File \"C:\\Users\\user\\gw-workspace\\KjR8z9Omiyus\\importing_multiprocessor.py\", line 25, in generate_masks_in_parallel\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\nNameError: name 'generate_segmentation_mask_from_file' is not defined\n",
  "history_begin_time" : 1664279332699,
  "history_end_time" : 1664279354156,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "d89i6a0fvci",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\nfrom subset_arrays import *\nfrom importing_logger import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "We assume pixel position of grid is centered for C:\\Users\\user\\ML_eddies\\cds_ssh_2019_10day_interval\\dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 987 files for 1998-2018.\nTraceback (most recent call last):\n  File \"train_test_subsets.py\", line 4, in <module>\n    from importing_logger import *\n  File \"C:\\Users\\user\\gw-workspace\\d89i6a0fvci\\importing_logger.py\", line 17, in <module>\n    train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n  File \"C:\\Users\\user\\gw-workspace\\d89i6a0fvci\\importing_multiprocessor.py\", line 25, in generate_masks_in_parallel\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\nNameError: name 'generate_segmentation_mask_from_file' is not defined\n",
  "history_begin_time" : 1664279174232,
  "history_end_time" : 1664279192708,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "XUjJ9Q41CdUi",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\nfrom subset_arrays import *\nfrom importing_logger import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "We assume pixel position of grid is centered for C:\\Users\\user\\ML_eddies\\cds_ssh_2019_10day_interval\\dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 987 files for 1998-2018.\nTraceback (most recent call last):\n  File \"train_test_subsets.py\", line 4, in <module>\n    from importing_logger import *\n  File \"C:\\Users\\user\\gw-workspace\\XUjJ9Q41CdUi\\importing_logger.py\", line 17, in <module>\n    train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n  File \"C:\\Users\\user\\gw-workspace\\XUjJ9Q41CdUi\\importing_multiprocessor.py\", line 25, in generate_masks_in_parallel\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\nNameError: name 'generate_segmentation_mask_from_file' is not defined\n",
  "history_begin_time" : 1664278863621,
  "history_end_time" : 1664278907274,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "LFjdA8EmL29U",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\nfrom subset_arrays import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 9, in <module>\n    train_masks,\nNameError: name 'train_masks' is not defined\n",
  "history_begin_time" : 1664278724301,
  "history_end_time" : 1664278780817,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "z94drkzlik9",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 7, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1664278559179,
  "history_end_time" : 1664278568524,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6ul9es8i7wo",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 7, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1664278255821,
  "history_end_time" : 1664278264371,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "heh3psu1cqk",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 7, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1664277116660,
  "history_end_time" : 1664277125322,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "j9yleplu9c3",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 7, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1664276506570,
  "history_end_time" : 1664276514107,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "yibqdtyrvg7",
  "history_input" : "# defining the longitude and latitude range, train subset and test subset\nfrom eddy_import import *\n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 7, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1664216946196,
  "history_end_time" : 1664216955392,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "0fwcez0dl8g",
  "history_input" : "def generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files\n\n# training set: 1998 - 2018\ntrain_dates, train_files = get_dates_and_files(\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n)\n\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  \n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 91, in <module>\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\nNameError: name 'train_folder' is not defined\n",
  "history_begin_time" : 1664211549554,
  "history_end_time" : 1664211551199,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "epfw0q6pvjr",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/epfw0q6pvjr/train_test_subsets.py\", line 5, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1663777424071,
  "history_end_time" : 1663777424179,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ef6tsw013bk",
  "history_input" : "def generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files\n\n# training set: 1998 - 2018\ntrain_dates, train_files = get_dates_and_files(\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n)\n\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  \n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 91, in <module>\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\nNameError: name 'train_folder' is not defined\n",
  "history_begin_time" : 1663682196698,
  "history_end_time" : 1663682199530,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "h0c1zsba8ux",
  "history_input" : "def generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files\n\n# training set: 1998 - 2018\ntrain_dates, train_files = get_dates_and_files(\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n)\n\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  \n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 91, in <module>\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\nNameError: name 'train_folder' is not defined\n",
  "history_begin_time" : 1663680971723,
  "history_end_time" : 1663680974221,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "bch3lnh0lj5",
  "history_input" : "def generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files\n\n# training set: 1998 - 2018\ntrain_dates, train_files = get_dates_and_files(\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n)\n\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  \n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 91, in <module>\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\nNameError: name 'train_folder' is not defined\n",
  "history_begin_time" : 1663679455084,
  "history_end_time" : 1663679457126,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "DkghTJX0yW4i",
  "history_input" : "def generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files\n\n# training set: 1998 - 2018\ntrain_dates, train_files = get_dates_and_files(\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n)\n\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  \n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 91, in <module>\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\nNameError: name 'train_folder' is not defined\n",
  "history_begin_time" : 1663679390581,
  "history_end_time" : 1663679391930,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "eu9qlmJK2Cw7",
  "history_input" : "# training set: 1998 - 2018\ntrain_dates, train_files = get_dates_and_files(\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n)\n\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  \n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 2, in <module>\n    train_dates, train_files = get_dates_and_files(\nNameError: name 'get_dates_and_files' is not defined\n",
  "history_begin_time" : 1663679366866,
  "history_end_time" : 1663679368392,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "h6ViParhQSpE",
  "history_input" : "# training set: 1998 - 2018\ntrain_dates, train_files = get_dates_and_files(\n    range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n)\n\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  \n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 2, in <module>\n    train_dates, train_files = get_dates_and_files(\nNameError: name 'get_dates_and_files' is not defined\n",
  "history_begin_time" : 1663678679494,
  "history_end_time" : 1663678680960,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "KKhXgqmdErVL",
  "history_input" : "def subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  \n# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 112, in <module>\n    train_masks,\nNameError: name 'train_masks' is not defined\n",
  "history_begin_time" : 1663678465457,
  "history_end_time" : 1663678467055,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ibdiAZ5eeXvb",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"C:\\Users\\user\\gw-workspace\\ibdiAZ5eeXvb\\train_test_subsets.py\", line 5, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1663678427906,
  "history_end_time" : 1663678429720,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "3t1k8kx245z",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 5, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1663678074801,
  "history_end_time" : 1663678077785,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "h0vqzy8utyl",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 5, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1663677934407,
  "history_end_time" : 1663677936188,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "lmt3mynejwl",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 5, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1663677738338,
  "history_end_time" : 1663677740181,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "eck0hfphn5m",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/joe/gw-workspace/eck0hfphn5m/train_test_subsets.py\", line 5, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1663593228168,
  "history_end_time" : 1663593228259,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "sdth6wzz07z",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 5, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1663183496607,
  "history_end_time" : 1663183498104,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "568mlt36eqw",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Traceback (most recent call last):\n  File \"train_test_subsets.py\", line 5, in <module>\n    train_subset = subset_arrays(\nNameError: name 'subset_arrays' is not defined\n",
  "history_begin_time" : 1663183394689,
  "history_end_time" : 1663183396215,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "tnqzklwy8x4",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1663182768300,
  "history_end_time" : 1663182768409,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "3fig59irg5a",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1663182735585,
  "history_end_time" : 1663182735815,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "838f4eoh644",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1663182674466,
  "history_end_time" : 1663182674630,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xygjwg1qhlq",
  "history_input" : "# northern pacific (32x32 degree -> 128x128 pixels)\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)\n",
  "history_output" : "Cannot run program \"python3.8\" (in directory \"C:\\Users\\user\\gw-workspace\\xygjwg1qhlq\"): CreateProcess error=2, The system cannot find the file specified",
  "history_begin_time" : 1663034980863,
  "history_end_time" : 1663034982835,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "e996wkht201",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664279406345,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "hxbizkvc2tu",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664324117022,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "02y62uyaeaw",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664324237727,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "0yd7603dedm",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664324597709,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "zfzd8j2hcw9",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664325180209,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gcvs9iha52y",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664327829336,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "br5jcn4nj7h",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664333600370,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "bohoicdifbx",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664362462030,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "pvfw4e3s3up",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664363357320,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "vt6fbmytcpi",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664364123123,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "4039h0t9qpb",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664372085391,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "k2wkwvq4dnh",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664373328816,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "jne763o62rj",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665244616480,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gxsgd2x94fv",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665245509403,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "5o8kobkzekq",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665253907634,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "2d17aq6ojn2",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665454136958,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "92bjjeyo5pb",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665492180745,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Stopped"
},]
