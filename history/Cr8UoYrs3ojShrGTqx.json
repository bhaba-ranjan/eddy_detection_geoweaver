[{
  "history_id" : "e4bivmzilrs",
  "history_input" : "#Importing required libraries, inserting the system paths, fixing manual seeds for reproducibility\nfrom eddy_import import *\nimport os\nimport sys\nsys.path.insert(0, os.path.dirname(os.getcwd()))\n\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"   # useful on multi-GPU systems with multiple users\n\n# Fix manual seeds for reproducibility\nimport torch\nseed = 42\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)",
  "history_output" : "",
  "history_begin_time" : 1674567094762,
  "history_end_time" : 1674567102172,
  "history_notes" : null,
  "history_process" : "slycsi",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1cldylsmjg0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510473,
  "history_end_time" : 1674566510473,
  "history_notes" : null,
  "history_process" : "3hm7db",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yg72qyxfhkx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510477,
  "history_end_time" : 1674566510477,
  "history_notes" : null,
  "history_process" : "98bbcl",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "367qw0sl08u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510479,
  "history_end_time" : 1674566510479,
  "history_notes" : null,
  "history_process" : "ljp3lh",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "0vmakmp9pqy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510481,
  "history_end_time" : 1674566510481,
  "history_notes" : null,
  "history_process" : "w484ne",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bz40yymaow4",
  "history_input" : "#Evaluate model on training and validation sets\n#from eddy_import import *\n\n#from pytorch_local import *\n#from trainingModel import *\n#from tensorboard_logger import *\nfrom IPython.display import display, HTML\nimport torch\nfrom matplotlib.animation import ArtistAnimation\n\ndef mainFunction():\n  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n  model.eval()\n  with torch.no_grad():\n      fig, ax = plt.subplots(1, 3, figsize=(25, 10))\n      artists = []\n      # loop through all SSH maps and eddy masks in 2019\n      # and run the model to generate predicted eddy masks\n      for n, (ssh_vars, seg_masks, date_indices) in enumerate(val_loader):\n          ssh_vars = ssh_vars.to(device)\n          seg_masks = seg_masks.to(device)\n          # Run the model to generate predictions\n          preds = model(ssh_vars)\n\n          # For each pixel, EddyNet outputs predictions in probabilities, \n          # so choose the channels (0, 1, or 2) with the highest prob. \n          preds = preds.argmax(dim=1)\n        \n          # Loop through all SSH maps, eddy masks, and predicted masks\n          # in this minibatch and generate a video\n          preds = preds.cpu().numpy()\n          seg_masks = seg_masks.cpu().numpy()\n          ssh_vars = ssh_vars.cpu().numpy()\n          date_indices = date_indices.cpu().numpy()\n          for i in range(len(ssh_vars)):\n              date, img, mask, pred = date_indices[i], ssh_vars[i], seg_masks[i], preds[i]\n              img1, title1, img2, title2, img3, title3 = plot_eddies_on_axes(\n                date, img, mask, pred, ax[0], ax[1], ax[2]\n              )\n              artists.append([img1, title1, img2, title2, img3, title3])\n              fig.canvas.draw()\n              fig.canvas.flush_events()\n      animation = ArtistAnimation(fig, artists, interval=200, blit=True)\n      plt.close()\n    \n  animation.save(os.path.join(tensorboard_dir, \"val_predictions.gif\"), writer=\"pillow\")\n  HTML(animation.to_jshtml())\n\n  plt.savefig(f'{figOutputFolder}/Animations.png', bbox_inches =\"tight\")\n\nif __name__ == \"__main__\":\n  mainFunction()",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/bz40yymaow4/animation.py\", line 52, in <module>\n    mainFunction()\n  File \"/Users/lakshmichetana/gw-workspace/bz40yymaow4/animation.py\", line 13, in mainFunction\n    model.eval()\nNameError: name 'model' is not defined\n",
  "history_begin_time" : 1674567116206,
  "history_end_time" : 1674567117386,
  "history_notes" : null,
  "history_process" : "ohe0x9",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "jp2btpm3orr",
  "history_input" : "#Demonstrate the beginnings of how one can use classical computer vision techniques to recover eddy contours from the predicted segnmentation masks.\n\n#from eddy_import import *\nfrom animation import *\n\ndef mainFunction():\n  print(\"starting to import\")\n  print('importing done')\n  p = preds[0].astype(np.uint8)\n\n  print(f\"Number of anticyclonic eddies: {count_eddies(p, eddy_type='anticyclonic')}\")\n  print(f\"Number of cyclonic eddies: {count_eddies(p, eddy_type='cyclonic')}\")\n  print(f\"Number of both eddies: {count_eddies(p, eddy_type='both')}\")\n\n  # draw contours on the image\n  thr = cv2.threshold(p, 0, 1, cv2.THRESH_BINARY)[1].astype(np.uint8)\n  contours, hierarchy = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n  img = np.zeros(p.shape, np.uint8)\n  cv2.drawContours(img, contours, -1, (255, 255, 255), 1)\n  plt.imshow(img, cmap=\"gray\")\n  plt.axis(\"off\")\n\n  # get average contour area\n  area = 0\n  for cnt in contours:\n      area += cv2.contourArea(cnt)\n  area /= len(contours)\n  print(f\"Average contour area: {area:.2f} sq. pixels\")\n      \n  plt.savefig(f'{figOutputFolder}/EddyContours.png', bbox_inches =\"tight\")\n  \nif __name__ == \"__main__\":\n  mainFunction()\n",
  "history_output" : "starting to import\nimporting done\nTraceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/jp2btpm3orr/cyclic_anticyclonic_eddies.py\", line 33, in <module>\n    mainFunction()\n  File \"/Users/lakshmichetana/gw-workspace/jp2btpm3orr/cyclic_anticyclonic_eddies.py\", line 9, in mainFunction\n    p = preds[0].astype(np.uint8)\nNameError: name 'preds' is not defined\n",
  "history_begin_time" : 1674567119349,
  "history_end_time" : 1674567120295,
  "history_notes" : null,
  "history_process" : "kaedp2",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "qja78ono6lw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510547,
  "history_end_time" : 1674566510547,
  "history_notes" : null,
  "history_process" : "nzmtjk",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "u0vgnpqm1r7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510556,
  "history_end_time" : 1674566510556,
  "history_notes" : null,
  "history_process" : "6gs3ym",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bj59gmn6bz4",
  "history_input" : "# Defining the start_axes, update_axes, plot_variabe  and setting the paths for eddy workflow\nfrom eddy_import import *\n\ndef start_axes(title):\n    fig = plt.figure(figsize=(13, 5))\n    ax = fig.add_axes([0.03, 0.03, 0.90, 0.94])\n    ax.set_aspect(\"equal\")\n    ax.set_title(title, weight=\"bold\")\n    return ax\n\n\ndef update_axes(ax, mappable=None):\n    ax.grid()\n    if mappable:\n        plt.colorbar(mappable, cax=ax.figure.add_axes([0.94, 0.05, 0.01, 0.9]))\n\n\ndef plot_variable(grid_object, var_name, ax_title, **kwargs):\n    ax = start_axes(ax_title)\n    m = grid_object.display(ax, var_name, **kwargs)\n    update_axes(ax, m)\n    ax.set_xlim(grid_object.x_c.min(), grid_object.x_c.max())\n    ax.set_ylim(grid_object.y_c.min(), grid_object.y_c.max())\n    return ax, m\n\ndata_root = os.path.join(os.path.expanduser(\"~\"), \"ML_eddies\")\ntrain_folder = os.path.join(data_root, \"cds_ssh_1998-2018_10day_interval\")\ntest_folder = os.path.join(data_root, \"cds_ssh_2019_10day_interval\")\n\nexample_file = os.path.join(test_folder, \"dt_global_twosat_phy_l4_20190101_vDT2021.nc\")\ndate = datetime(2019, 1, 1)\ng = RegularGridDataset(example_file, \"longitude\", \"latitude\")\n\nfigOutputFolder = '/Users/lakshmichetana/ML_Eddies_New_Data_Output/'\n",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\n",
  "history_begin_time" : 1674566510657,
  "history_end_time" : 1674566518336,
  "history_notes" : null,
  "history_process" : "23nut7",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2r6idf4f9u3",
  "history_input" : "# setting the vmin and vmax using the eddy 'plot_variable' method\n#from eddy_paths import *\nfrom eddy_paths import figOutputFolder, plot_variable, g\nfrom copy import deepcopy\nfrom matplotlib import pyplot as plt\n\n#updated the vmin and vmax to -1 and 1\nax, m = plot_variable(\n    g,\n    \"adt\",\n    f\"ADT (m) before high-pass filter\",\n    vmin=-1,\n    vmax=1,\n)\nplt.savefig(f'{figOutputFolder}/ADT(m)_before_high-pass_filter.png', bbox_inches =\"tight\")\n#updated wavelength covered kilometers to 500 from 700\nwavelength_km = 500\n\ng_filtered = deepcopy(g)\n\ng_filtered.bessel_high_filter(\"adt\", wavelength_km)\nax, m = plot_variable(\n    g_filtered,\n    \"adt\",\n    f\"ADT (m) filtered (Final: {wavelength_km} km)\",\n    vmin=-1,\n    vmax=1,\n)\n\nplt.savefig(f'{figOutputFolder}/ADT(m)-filtered.png', bbox_inches =\"tight\")\n",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n",
  "history_begin_time" : 1674566519472,
  "history_end_time" : 1674566525381,
  "history_notes" : null,
  "history_process" : "zr8vzj",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3bur82sikst",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510584,
  "history_end_time" : 1674566510584,
  "history_notes" : null,
  "history_process" : "4bd5xp",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mkt1npsxnik",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510586,
  "history_end_time" : 1674566510586,
  "history_notes" : null,
  "history_process" : "l9f2t3",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "tj3es9d7edn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510589,
  "history_end_time" : 1674566510589,
  "history_notes" : null,
  "history_process" : "4o6voy",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yl2i3sv32u6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510590,
  "history_end_time" : 1674566510590,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "j56tn76imqv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510593,
  "history_end_time" : 1674566510593,
  "history_notes" : null,
  "history_process" : "39ur7y",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "igjtlr5cxew",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510595,
  "history_end_time" : 1674566510595,
  "history_notes" : null,
  "history_process" : "uolls4",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "79axkovlygv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510596,
  "history_end_time" : 1674566510596,
  "history_notes" : null,
  "history_process" : "oc42ub",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "erc57q69f3z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510601,
  "history_end_time" : 1674566510601,
  "history_notes" : null,
  "history_process" : "bzgeyy",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "m6ofiqn18wn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1674566510605,
  "history_end_time" : 1674566510605,
  "history_notes" : null,
  "history_process" : "bomi2j",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "47074k6ctov",
  "history_input" : "#getting the test dates and files of training sets from 1998 - 2018 and from training set 2019 and also setting the logging level as ERROR\nfrom eddy_import import *\nfrom importing_multiprocessor import *\nfrom eddy_paths import *\nfrom eddy_plots import *\nimport logging\nfrom subset_arrays import *\n#from Generate_Masks import *\n# northern pacific (32x32 degree -> 128x128 pixels)\n\ndef funcGenerateMasks():\n  logging.getLogger(\"pet\").setLevel(logging.ERROR)\n\n    # enter the AVISO filename pattern\n    # year, month, and day in file_pattern will be filled in get_dates_and_files:\n  file_pattern = \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n  # training set: 1998 - 2018\n  train_dates, train_files = get_dates_and_files(\n      range(2000, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n  )\n  train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n      train_files, train_dates\n  )\n\n\n# test set: 2019\n  test_dates, test_files = get_dates_and_files(\n      [2019], range(1, 13), [1, 10, 20, 30], test_folder, file_pattern\n  )\n  test_adt, test_adt_filtered, test_masks = generate_masks_in_parallel(\n      test_files, test_dates\n  )\n\n\n  lon_range = (-166, -134)\n  lat_range = (14, 46)\n\n  train_subset = subset_arrays(\n      train_masks,\n      train_adt,\n      train_adt_filtered,\n      train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n  )\n\n  test_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n  )\n\n  plt.savefig(f'{figOutputFolder}/Train_Test_Subset_Img.png', bbox_inches =\"tight\")\n\nif __name__ == \"__main__\":\n  funcGenerateMasks()\n",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 893 files for 2000-2018.\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20000101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20000410_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20000710_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20001010_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20010110_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20010420_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20010720_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20011020_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20020120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20020430_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20020730_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20021030_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20030130_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20030501_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20030801_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20031101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040201_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040510_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040810_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20041110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20050210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20050520_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20050820_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20051120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20060220_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20060530_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20060830_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20061130_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070301_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070601_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070901_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20071201_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20080310_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20080610_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20080910_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20081210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20090320_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20090620_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20090920_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20091220_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20100330_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20100630_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20100930_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20101230_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20110401_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20110701_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20111001_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20120101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20120410_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20120710_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20121010_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20130110_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20130420_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20130720_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20131020_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20140120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20140430_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20140730_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20141030_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20150130_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20150501_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20150801_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20151101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20160201_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20160510_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20160810_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20161110_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20170210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20170520_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20170820_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20171120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20180220_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20180530_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20180830_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20181130_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo extrema found in contour of 6 pixels in level 0.010000\nNo extrema found in contour of 4 pixels in level 0.015000\nNo extrema found in contour of 4 pixels in level 0.020000\nNo extrema found in contour of 4 pixels in level 0.055000\nNo extrema found in contour of 4 pixels in level 0.075000\nNo extrema found in contour of 4 pixels in level 0.015000\nNo extrema found in contour of 4 pixels in level -0.010000\nNo extrema found in contour of 4 pixels in level -0.010000\nNo extrema found in contour of 4 pixels in level -0.035000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20041120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20100701_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20001020_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20061201_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20031110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070610_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20110410_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20030201_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20030510_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20071210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20000420_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20010430_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n",
  "history_begin_time" : 1674566575808,
  "history_end_time" : 1674567094021,
  "history_notes" : null,
  "history_process" : "uji5d1",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nh7cehurhcl",
  "history_input" : "from file_paths import *\nfrom declaring_epochs_size import *\nfrom data_utils import get_eddy_dataloader\nfrom eddy_import import *\nimport numpy as np\nimport torch\nfrom get_eddy_dataloader import *\nfrom eddynet import EddyNet\nfrom eddy_paths import figOutputFolder\n\n# set binary = false if we want to distinguish between cyclonic and anticyclonic\nbinary = False\nnum_classes = 2 if binary else 3\ntrain_loader, _ = get_eddy_dataloader(train_file, binary=binary, batch_size=batch_size)\nval_loader, _ = get_eddy_dataloader(\n    val_file, binary=binary, batch_size=batch_size, shuffle=False\n)\n\n#Looking at the distribution of class frequencies to identify class imbalances\ntrain_masks = train_loader.dataset.masks.copy()\nclass_frequency = np.bincount(train_masks.flatten())\ntotal_pixels = sum(class_frequency)\nprint(\n    f\"Total number of pixels in training set: {total_pixels/1e6:.2f} megapixels\"\n    f\" across {len(train_masks)} SSH maps\\n\"\n    f\"Number of pixels that are not eddies: {class_frequency[0]/1e6:.2f} megapixels \"\n    f\"({class_frequency[0]/total_pixels * 100:.2f}%)\\n\"\n    f\"Number of pixels that are anticyclonic eddies: {class_frequency[1]/1e6:.2f} megapixels \"\n    f\"({class_frequency[1]/total_pixels * 100:.2f}%)\\n\"\n    f\"Number of pixels that are cyclonic eddies: {class_frequency[2]/1e6:.2f} megapixels \"\n    f\"({class_frequency[2]/total_pixels * 100:.2f}%)\\n\"\n)\n\n#Using plot_sample to visualize the dataset we just loaded.\ntrain_loader.dataset.plot_sample(N=3)\nplt.savefig(f\"{figOutputFolder}/datasetPlots\",bbox=\"tight\")\n\n#Segmentation Model:\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available(): \n    model.to(device=\"cuda\")",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\n/Users/lakshmichetana/gw-workspace/nh7cehurhcl/EddyDataLoader_PixelTraining_TrainingDataset_&_Pytorch.py:36: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox\" which is no longer supported as of 3.3 and will become an error in 3.6\n  plt.savefig(f\"{figOutputFolder}/datasetPlots\",bbox=\"tight\")\nRead 987 samples from /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 47 samples from /Users/lakshmichetana/ML_eddies/dataset-satellite-sea-level-global-601bf215-53f9-47ac-bb7f-690c0c65c7c3/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\nRead 987 samples from /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 47 samples from /Users/lakshmichetana/ML_eddies/dataset-satellite-sea-level-global-601bf215-53f9-47ac-bb7f-690c0c65c7c3/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\nTotal number of pixels in training set: 16.17 megapixels across 987 SSH maps\nNumber of pixels that are not eddies: 11.71 megapixels (72.43%)\nNumber of pixels that are anticyclonic eddies: 2.33 megapixels (14.39%)\nNumber of pixels that are cyclonic eddies: 2.13 megapixels (13.18%)\n",
  "history_begin_time" : 1674567104116,
  "history_end_time" : 1674567109096,
  "history_notes" : null,
  "history_process" : "qsxf3a",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9twxn3td47s",
  "history_input" : "#loss function\nprint('start imports')\n#import torch\nprint('torch')\n#from eddy_import import *\nprint('eddy_import')\nfrom pytorch_local import *\nprint('pytorch_local')\nfrom data_utils import *\nprint('get_eddy_dataloader')\nimport torchmetrics\nprint('torchmetrics')\nimport datetime\nprint('datetime')\nfrom torch.utils.tensorboard import SummaryWriter\nprint('SummaryWriter')\nimport cv2  # use cv2 to count eddies by drawing contours around segmentation masks\nprint('cv2')\nimport matplotlib.pyplot as plt\nprint('matplotlib.pyplot')\n#import numpy as np\n\nfrom tqdm.auto import tqdm\nprint('tqdm.auto ')\nfrom eddy_train_utils import run_batch, write_metrics_to_tensorboard, filter_scalar_metrics, EarlyStopping\nprint('end of imports')\n\n#Run the training loop for prescribed num_epochs\nfrom declaring_epochs_size import *\nfrom eddy_train_utils import add_hparams\n\n\ndef mainFunction():\n  print('Before Loss Function')\n  loss_fn = torch.nn.CrossEntropyLoss()\n  print('After loss Function')\n  # TODO (homework): Try \n  # loss_fn =    torch.nn.CrossEntropyLoss(weight=torch.Tensor(total_pixels/class_frequency))\n\n  # learning rate for use in OneCycle scheduler\n  initial_lr = 1e-6\n  max_lr = 5e-4\n\n  print('Before scheduler initiation')\n  optimizer = torch.optim.Adam(model.parameters(), lr=max_lr)\n  scheduler = torch.optim.lr_scheduler.OneCycleLR(\n      optimizer,\n      max_lr=max_lr,\n      steps_per_epoch=len(train_loader),\n      epochs=num_epochs,\n      div_factor=max_lr / initial_lr,\n      pct_start=0.3,\n  )\n  print('after scheduler initiation')\n\n  #Defining and using the get_metrics function\n  def get_metrics(N, sync=False):\n      \"\"\"Get the metrics to be used in the training loop.\n      Args:\n          N (int): The number of classes.\n          sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n      Returns:\n          train_metrics (MetricCollection): The metrics to be used in the training loop.\n          val_metrics (MetricCollection): The metrics to be used in validation.\n      \"\"\"\n      # Define metrics and move to GPU if available\n      metrics = [\n          torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n          torchmetrics.Precision(\n              average=None,\n              dist_sync_on_step=sync,\n              num_classes=N,\n          ),\n          torchmetrics.Recall(\n              average=None,\n              dist_sync_on_step=sync,\n              num_classes=N,\n          ),\n#           torchmetrics.F1Score(  # TODO: Homework: verify in tensorboard that this is equivalent to accuracy\n#               average=\"micro\",\n#               dist_sync_on_step=sync,\n#               num_classes=N,\n#           ),\n          torchmetrics.F1Score(\n              average=\"none\",  # return F1 for each class\n              dist_sync_on_step=sync,\n              num_classes=N,\n          )\n      ]\n      if torch.cuda.is_available():  # move metrics to the same device as model\n          [metric.to(\"cuda\") for metric in metrics]\n\n      train_metrics = torchmetrics.MetricCollection(metrics)\n      val_metrics = train_metrics.clone()\n      return train_metrics, val_metrics\n\n  train_metrics, val_metrics = get_metrics(num_classes)\n\n\n#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\n  import datetime\n  print('before tensorboard dir')\n  tensorboard_dir = os.path.join(\n      os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n      \"tensorboard\",\n      # add current timestamp\n      f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n  )\n  writer = SummaryWriter(log_dir=tensorboard_dir)\n  print(\n      f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n      f\"Writing Tensorboard logs to {writer.log_dir}\"\n      f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n  )\n  print('after tensorboard dir')\n\n  #Train the model: Defining training loop\n\n  num_plots_in_tensorboard = 5\n  # will populate this later with random numbers:\n  random_plot_indices = np.zeros((num_plots_in_tensorboard,), np.uint8)\n\n  print('before run_epoch')\n  def run_epoch(\n      epoch,\n      model,\n      loss_fn,\n      optimizer,\n      scheduler,\n      train_loader,\n      val_loader,\n      train_metrics,\n      val_metrics,\n      writer,\n  ):\n      leave = epoch == num_epochs - 1  # leave progress bar on screen after last epoch\n\n      model.train()\n      # training set\n      for batch_num, (gvs, seg_masks, date_indices) in enumerate(train_loader):\n          train_loss = run_batch(\n              model, loss_fn, gvs, seg_masks, optimizer, scheduler, train_metrics\n          )\n          iter_num = epoch * len(train_loader) + batch_num\n          writer.add_scalar(\"train/lr\", scheduler.get_last_lr()[-1], iter_num)\n\n      # validation set\n      images, preds, labels, dates = [], [], [], []\n      model.eval()\n      with torch.no_grad():\n          val_loss = num_examples = 0\n          for gvs, masks, date_indices in val_loader:\n              # continue\n              loss_, pred_batch = run_batch(\n                  model, loss_fn, gvs, masks, metrics=val_metrics, return_pred=True\n              )\n              val_loss += loss_\n              num_examples += np.prod(gvs.shape)\n              # keep track of images, preds, labels for plotting\n              images.append(gvs)\n              preds.append(pred_batch)\n              labels.append(masks)\n              dates.append(date_indices)\n\n      # calculate average validation loss across all samples\n      # num_examples should be equal to sum of all pixels\n      val_loss = val_loss / num_examples\n\n      # plot validation images and log to tensorboard\n      ## move images, preds, labels, dates to cpu\n      images = torch.cat(images).cpu().numpy()\n      labels = torch.cat(labels).cpu().numpy()\n      preds = torch.cat(preds).cpu().numpy()\n      dates = torch.cat(dates).cpu().numpy()\n      ## convert indices to actual dates\n      dates = [val_loader.dataset.dates[i].strftime(\"%Y-%m-%d\") for i in dates]\n\n      # take random images from validation set\n      if epoch == 0:\n          indices_ = np.random.choice(\n              len(images), num_plots_in_tensorboard, replace=False\n          )\n          for i, idx in enumerate(indices_):\n              random_plot_indices[i] = idx\n      fig, ax = plt.subplots(num_plots_in_tensorboard, 3, figsize=(20, 30))\n      for n, i in enumerate(random_plot_indices):\n          date, img, mask, pred = dates[i], images[i], labels[i], preds[i]\n          artists = plot_eddies_on_axes(\n              date, img, mask, pred, ax[n, 0], ax[n, 1], ax[n, 2]\n          )\n      plt.tight_layout()\n      writer.add_figure(f\"val/sample_prediction\", fig, global_step=epoch)\n\n      # Update tensorboard\n      train_m = write_metrics_to_tensorboard(\n          num_classes, train_metrics, writer, epoch, \"train\"\n      )\n      val_m = write_metrics_to_tensorboard(num_classes, val_metrics, writer, epoch, \"val\")\n\n      writer.add_scalar(\"train/loss\", train_loss, epoch)\n      writer.add_scalar(\"val/loss\", val_loss, epoch)\n\n      # reset metrics after each epoch\n      train_metrics.reset()\n      val_metrics.reset()\n\n      train_m = filter_scalar_metrics(train_m)\n      val_m = filter_scalar_metrics(val_m)\n\n      return train_loss, val_loss, train_m, val_m\n  print('after run_epoch')\n\n  def plot_eddies_on_axes(date, img, mask, pred, a1, a2, a3):\n      im1 = a1.imshow(img.squeeze(), cmap=\"viridis\")\n\n      # blit canvas for a1 a2 a3\n      a1.figure.canvas.draw()\n      a1.figure.canvas.flush_events()\n      a2.figure.canvas.draw()\n      a2.figure.canvas.flush_events()\n      a3.figure.canvas.draw()\n      a3.figure.canvas.flush_events()\n\n      # https://stackoverflow.com/a/49159236\n      t1 = a1.text(\n          0.5,\n          1.05,\n          f\"ADT {date}\",\n          size=plt.rcParams[\"axes.titlesize\"],\n          ha=\"center\",\n          transform=a1.transAxes,\n      )\n      # set axis off\n      a1.axis(\"off\")\n\n      # count number of eddies in mask and pred\n      mask_anticyclonic = count_eddies(mask, \"anticyclonic\")\n      mask_cyclonic = count_eddies(mask, \"cyclonic\")\n      pred_anticyclonic = count_eddies(pred, \"anticyclonic\")\n      pred_cyclonic = count_eddies(pred, \"cyclonic\")\n\n      # calculate accuracy between pred and mask\n      acc = np.sum(pred == mask) / mask.size\n      im2 = a2.imshow(pred, cmap=\"viridis\")\n      t2 = a2.text(\n          0.5,\n          1.05,\n          (\n              f\"Prediction (Acc = {acc:.3f} |\"\n              f\" Num. anticyclonic = {pred_anticyclonic} |\"\n              f\" Num. cyclonic = {pred_cyclonic})\"\n          ),\n          size=plt.rcParams[\"axes.titlesize\"],\n          ha=\"center\",\n          transform=a2.transAxes,\n      )\n      a2.axis(\"off\")\n      im3 = a3.imshow(mask, cmap=\"viridis\")\n      t3 = a3.text(\n          0.5,\n          1.05,\n          (\n              f\"Ground Truth\"\n              f\" (Num. anticyclonic: {mask_anticyclonic} |\"\n              f\" Num. cyclonic: {mask_cyclonic})\"\n          ),\n          size=plt.rcParams[\"axes.titlesize\"],\n          ha=\"center\",\n          transform=a3.transAxes,\n      )\n      a3.axis(\"off\")\n\n      return im1, t1, im2, t2, im3, t3\n\n\n  def count_eddies(arr, eddy_type=\"both\"):\n      mask = np.zeros(arr.shape, dtype=np.uint8)\n      if eddy_type == \"anticyclonic\":\n          mask[arr == 1] = 1\n      elif eddy_type == \"cyclonic\":\n          mask[arr == 2] = 1\n      else:\n          mask[arr > 0] = 1\n      contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n      return len(contours)\n\n# create some aliases\n  loss, opt, sched = loss_fn, optimizer, scheduler\n  num_epochs = 5\n\n  checkpoint_path = os.path.join(tensorboard_dir, \"model_ckpt_{epoch}.pt\")\n  early_stopping = EarlyStopping(\n      patience=10,\n      path=checkpoint_path,\n      min_epochs=30,\n  )\n\n  progress_bar = tqdm(range(num_epochs), desc=\"Training: \", unit=\"epoch(s)\")\n  for N in progress_bar:\n      train_loss, val_loss, train_m, val_m = run_epoch(\n          N,\n          model,\n          loss,\n          opt,\n          sched,\n          train_loader,\n          val_loader,\n          train_metrics,\n          val_metrics,\n          writer,\n      )\n\n      # update progress bar\n      train_m_copy = {f\"train_{k}\".lower(): v.cpu().numpy() for k, v in train_m.items()}\n      val_m_copy = {f\"val_{k}\".lower(): v.cpu().numpy() for k, v in val_m.items()}\n      progress_bar.set_postfix(**train_m_copy, **val_m_copy)\n\n      # early stopping when validation loss stops improving\n      early_stopping.path = checkpoint_path.format(epoch=N)\n      early_stopping(val_loss, model)\n      if early_stopping.early_stop:\n          print(\n              f\"Early stopping at epoch {N}\"\n              f\" with validation loss {val_loss:.3f}\"\n              f\" and training loss {train_loss:.3f}\"\n          )\n          break\n\n      # TODO (homework): save checkpoint every 10 epochs\n\n  # add hyperparameters and corresponding results to tensorboard HParams table\n  hparam_dict = {\n      \"backbone\": model_name,\n      \"num_epochs\": num_epochs,\n      \"batch_size\": batch_size,\n      \"num_classes\": num_classes,\n      \"binary_mask\": binary,\n      \"optimizer\": optimizer.__class__.__name__,\n      \"max_lr\": max_lr,\n      \"loss_function\": loss_fn.__class__.__name__,\n  }\n  metrics_dict = {\n      \"train/end_epoch\": N,\n      \"train/loss\": train_loss,\n      \"train/Accuracy\": train_m[\"Accuracy\"],\n      \"val/loss\": val_loss,\n      \"val/Accuracy\": val_m[\"Accuracy\"],\n  }\n  add_hparams(writer, hparam_dict, metrics_dict, epoch_num=N)\n  writer.close()\n\n  print('model path setting')\n  # save model to tensorboard folder\n  model_path = os.path.join(tensorboard_dir, f\"model_ckpt_{N+1}.pt\")\n  print('entering save option')\n  torch.save(model.state_dict(), model_path)\n\nif __name__ == \"__main__\":\n  mainFunction()",
  "history_output" : "start imports\ntorch\neddy_import\nRead 987 samples from /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 47 samples from /Users/lakshmichetana/ML_eddies/dataset-satellite-sea-level-global-601bf215-53f9-47ac-bb7f-690c0c65c7c3/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\npytorch_local\nget_eddy_dataloader\ntorchmetrics\ndatetime\nSummaryWriter\ncv2\nmatplotlib.pyplot\ntqdm.auto \nend of imports\nBefore Loss Function\nAfter loss Function\nBefore scheduler initiation\nTraceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/9twxn3td47s/LossFunction_LearningRate_MetricsEvaluation.py\", line 360, in <module>\n    mainFunction()\n  File \"/Users/lakshmichetana/gw-workspace/9twxn3td47s/LossFunction_LearningRate_MetricsEvaluation.py\", line 50, in mainFunction\n    epochs=num_epochs,\nUnboundLocalError: local variable 'num_epochs' referenced before assignment\n",
  "history_begin_time" : 1674567110230,
  "history_end_time" : 1674567114299,
  "history_notes" : null,
  "history_process" : "tldnzh",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "epkxy5u8wxx",
  "history_input" : "# setting the vmin and vmax using the eddy 'plot_variable' method\nfrom eddy_paths import *\nfrom copy import deepcopy\nfrom matplotlib import pyplot as plt\n\n#updated the vmin and vmax to -1 and 1\nax, m = plot_variable(\n    g,\n    \"adt\",\n    f\"ADT (m) before high-pass filter\",\n    vmin=-5,\n    vmax=5,\n)\nplt.savefig(f'{figOutputFolder}/ADT(m)_before_high-pass_filter_with_updatedVminVmax&Wavelength_KM.png', bbox_inches =\"tight\")\n#updated wavelength covered kilometers to 100 from 700\nwavelength_km = 100\n\ng_filtered = deepcopy(g)\n\ng_filtered.bessel_high_filter(\"adt\", wavelength_km)\nax, m = plot_variable(\n    g_filtered,\n    \"adt\",\n    f\"ADT (m) filtered (Final: {wavelength_km} km)\",\n    vmin=-5,\n    vmax=5,\n)\n\nplt.savefig(f'{figOutputFolder}/ADT(m)-filtered_with_updatedVminVmax&Wavelength_KM.png', bbox_inches =\"tight\")\n",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n",
  "history_begin_time" : 1674566527411,
  "history_end_time" : 1674566531472,
  "history_notes" : null,
  "history_process" : "k3gm1y",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z3zpgccms7k",
  "history_input" : "#code for plotting segmentation masks, antcyclonic display, cyclonic display and updating the axis\nfrom eddy_plots import *\nfrom eddy_paths import *\nfrom copy import deepcopy\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Detected Eddies on ADT (m).png', bbox_inches =\"tight\")\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Segmentation Mask.png', bbox_inches =\"tight\")",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n",
  "history_begin_time" : 1674566533482,
  "history_end_time" : 1674566573751,
  "history_notes" : null,
  "history_process" : "2if9sm",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9t0mksu4eyt",
  "history_input" : "#code for plotting segmentation masks, antcyclonic display, cyclonic display and updating the axis\nfrom eddy_plots import *\nfrom eddy_paths import *\nfrom copy import deepcopy\n\n#updated the r4ef details and also the vmin and vmax values\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-5, vmax=5, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-250\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-250\n)\nax.legend()\nupdate_axes(ax)\n\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Detected Eddies on ADT (m)_with_UpdatedVminVmax&RefValues.png', bbox_inches =\"tight\")\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)\nplt.savefig(f'{figOutputFolder}/Segmentation Mask_with_UpdatedVminVmax&RefValues.png', bbox_inches =\"tight\")",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n",
  "history_begin_time" : 1674566575012,
  "history_end_time" : 1674567093752,
  "history_notes" : null,
  "history_process" : "xm5gfq",
  "host_id" : "100001",
  "indicator" : "Done"
}]
