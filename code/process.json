[{
  "id" : "slycsi",
  "name" : "imports_trainEvaluateEddyModel",
  "description" : null,
  "code" : "#Importing required libraries, inserting the system paths, fixing manual seeds for reproducibility\nfrom eddy_import import *\nimport os\nimport sys\nsys.path.insert(0, os.path.dirname(os.getcwd()))\n\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"   # useful on multi-GPU systems with multiple users\n\n# Fix manual seeds for reproducibility\nimport torch\nseed = 42\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "3hm7db",
  "name" : "declaring_epochs_size",
  "description" : null,
  "code" : "#defining the number of epochs and batch size\nfrom eddy_import import *\nnum_epochs = 250  # can lower this to save time\nbatch_size = 256  # can lower this if you get an out of memory error",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "98bbcl",
  "name" : "file_paths",
  "description" : null,
  "code" : "#setting the NPZ file paths\nfrom eddy_import import *\n\ndata_root = os.path.join(os.path.expanduser(\"~\"), \"ML_eddies\")\ntrain_folder = os.path.join(data_root, \"cds_ssh_1998-2018_10day_interval\")\n#updated val folder with the latest satellite data (january and feb 2022)\nval_folder = os.path.join(data_root, \"dataset-satellite-sea-level-global-601bf215-53f9-47ac-bb7f-690c0c65c7c3\")\ntrain_file = os.path.join(train_folder, \"subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz\")\nval_file = os.path.join(val_folder, \"subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz\")",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "ljp3lh",
  "name" : "defining_model",
  "description" : null,
  "code" : "#defining model\nfrom eddy_import import *\ndef model(x):\n    return 0",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "w484ne",
  "name" : "analyzeTrainingCurve",
  "description" : null,
  "code" : "#Analyze training curves in TensorBoard\n\nfrom eddy_import import *\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))\n\n%load_ext tensorboard\n%tensorboard --bind_all --logdir $writer.log_dir --port=6008  # the default is 6006 but we set it to 6009 to avoid conflicts with other notebooks",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "ohe0x9",
  "name" : "animation",
  "description" : null,
  "code" : "#Evaluate model on training and validation sets\n#from eddy_import import *\n\n#from pytorch_local import *\n#from trainingModel import *\n#from tensorboard_logger import *\nfrom IPython.display import display, HTML\nimport torch\nfrom matplotlib.animation import ArtistAnimation\n\ndef mainFunction():\n  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n  model.eval()\n  with torch.no_grad():\n      fig, ax = plt.subplots(1, 3, figsize=(25, 10))\n      artists = []\n      # loop through all SSH maps and eddy masks in 2019\n      # and run the model to generate predicted eddy masks\n      for n, (ssh_vars, seg_masks, date_indices) in enumerate(val_loader):\n          ssh_vars = ssh_vars.to(device)\n          seg_masks = seg_masks.to(device)\n          # Run the model to generate predictions\n          preds = model(ssh_vars)\n\n          # For each pixel, EddyNet outputs predictions in probabilities, \n          # so choose the channels (0, 1, or 2) with the highest prob. \n          preds = preds.argmax(dim=1)\n        \n          # Loop through all SSH maps, eddy masks, and predicted masks\n          # in this minibatch and generate a video\n          preds = preds.cpu().numpy()\n          seg_masks = seg_masks.cpu().numpy()\n          ssh_vars = ssh_vars.cpu().numpy()\n          date_indices = date_indices.cpu().numpy()\n          for i in range(len(ssh_vars)):\n              date, img, mask, pred = date_indices[i], ssh_vars[i], seg_masks[i], preds[i]\n              img1, title1, img2, title2, img3, title3 = plot_eddies_on_axes(\n                date, img, mask, pred, ax[0], ax[1], ax[2]\n              )\n              artists.append([img1, title1, img2, title2, img3, title3])\n              fig.canvas.draw()\n              fig.canvas.flush_events()\n      animation = ArtistAnimation(fig, artists, interval=200, blit=True)\n      plt.close()\n    \n  animation.save(os.path.join(tensorboard_dir, \"val_predictions.gif\"), writer=\"pillow\")\n  HTML(animation.to_jshtml())\n\n  plt.savefig(f'{figOutputFolder}/Animations.png', bbox_inches =\"tight\")\n\nif __name__ == \"__main__\":\n  mainFunction()",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "kaedp2",
  "name" : "cyclic_anticyclonic_eddies",
  "description" : null,
  "code" : "#Demonstrate the beginnings of how one can use classical computer vision techniques to recover eddy contours from the predicted segnmentation masks.\n\n#from eddy_import import *\nfrom animation import *\n\ndef mainFunction():\n  print(\"starting to import\")\n  print('importing done')\n  p = preds[0].astype(np.uint8)\n\n  print(f\"Number of anticyclonic eddies: {count_eddies(p, eddy_type='anticyclonic')}\")\n  print(f\"Number of cyclonic eddies: {count_eddies(p, eddy_type='cyclonic')}\")\n  print(f\"Number of both eddies: {count_eddies(p, eddy_type='both')}\")\n\n  # draw contours on the image\n  thr = cv2.threshold(p, 0, 1, cv2.THRESH_BINARY)[1].astype(np.uint8)\n  contours, hierarchy = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n  img = np.zeros(p.shape, np.uint8)\n  cv2.drawContours(img, contours, -1, (255, 255, 255), 1)\n  plt.imshow(img, cmap=\"gray\")\n  plt.axis(\"off\")\n\n  # get average contour area\n  area = 0\n  for cnt in contours:\n      area += cv2.contourArea(cnt)\n  area /= len(contours)\n  print(f\"Average contour area: {area:.2f} sq. pixels\")\n      \n  plt.savefig(f'{figOutputFolder}/EddyContours.png', bbox_inches =\"tight\")\n  \nif __name__ == \"__main__\":\n  mainFunction()\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "nzmtjk",
  "name" : "get_eddy_dataloader",
  "description" : null,
  "code" : "#Data utils code\nimport os\nfrom file_paths import *\nfrom declaring_epochs_size import *\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom matplotlib.animation import ArtistAnimation\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom tqdm.auto import tqdm\n\ntorch.manual_seed(42)\n\nfrom data_utils import get_eddy_dataloader\n\n# set binary = false if we want to distinguish between cyclonic and anticyclonic\nbinary = False\nnum_classes = 2 if binary else 3\ntrain_loader, _ = get_eddy_dataloader(train_file, binary=binary, batch_size=batch_size)\nval_loader, _ = get_eddy_dataloader(\n    val_file, binary=binary, batch_size=batch_size, shuffle=False\n)\n\ndef get_eddy_dataset(files, binary=None, transform=None, val_split=0):\n    masks, dates, _, var_filtered, lon, lat, npz_dict = read_npz_files(files)\n    print(f\"Read {len(masks)} samples from {files}.\")\n    if val_split > 0:\n        # split into training and validation sets (80% training, 20% validation)\n        train_idx, val_idx = train_test_split(\n            np.arange(len(masks)), test_size=val_split, random_state=42\n        )\n        train_ds = EddyDataset(\n            masks[train_idx],\n            var_filtered[train_idx],\n            dates[train_idx],\n            transform=transform,\n            binary_mask=binary,\n        )\n\n        val_ds = EddyDataset(\n            masks[val_idx],\n            var_filtered[val_idx],\n            dates[val_idx],\n            transform=transform,\n            binary_mask=binary,\n        )\n    else:\n        train_ds = EddyDataset(\n            masks, var_filtered, dates, transform=transform, binary_mask=binary\n        )\n        val_ds = None\n    return train_ds, val_ds\n\n\ndef read_npz_files(npz_files: list):\n    \"\"\"Load a list of npz files, concatenate, and return separate arrays for eddy segmentation\"\"\"\n    # load npz file into separate variables\n    if isinstance(npz_files, str):\n        npz_files = [npz_files]\n    npz_contents = [np.load(file, allow_pickle=True) for file in npz_files]\n    masks, dates, var, var_filtered, lon_subset, lat_subset = eddy_dict_to_vars(\n        npz_contents\n    )\n    return masks, dates, var, var_filtered, lon_subset, lat_subset, npz_contents\n\n\ndef eddy_dict_to_vars(npz_contents):\n    masks = np.concatenate(\n        [npz_content[\"masks\"] for npz_content in npz_contents], axis=0\n    )\n    dates = np.concatenate(\n        [npz_content[\"dates\"] for npz_content in npz_contents], axis=0\n    )\n    # var = np.concatenate([npz_content[\"var\"] for npz_content in npz_contents], axis=0)\n    var = None\n    var_filtered = np.concatenate(\n        [npz_content[\"var_filtered\"] for npz_content in npz_contents], axis=0\n    )\n    if \"lon_subset\" in npz_contents[0]:\n        lon_subset = np.concatenate(\n            [npz_content[\"lon_subset\"] for npz_content in npz_contents], axis=0\n        )\n        lat_subset = np.concatenate(\n            [npz_content[\"lat_subset\"] for npz_content in npz_contents], axis=0\n        )\n    else:\n        lon_subset = lat_subset = None\n    return masks, dates, var, var_filtered, lon_subset, lat_subset\n\n\nclass EddyDataset(torch.utils.data.Dataset):\n    def __init__(self, masks, gv, dates, transform=None, binary_mask=False):\n        \"\"\"PyTorch dataset for eddy detection\n        Args:\n            masks (np.array): array of segmentation masks with shape: (N_dates, N_lon, N_lat)\n                Can have 3 values: 0, 1 and 2, where 1 = anticyclonic, 2 = cyclonic and 0 = no eddy\n            gv (np.array): array of GV maps with shape: (N_dates, N_lon, N_lat)\n                Example GVs: sea level anomaly, absolute dynamic topography\n            transform (callable, optional): Transformation to be applied on a sample.\n            binary_mask (bool, optional): If true, all eddies (anticyclonic and cyclonic) will be assigned a value of 1\n        \"\"\"\n        self.masks = masks\n        self.gv = gv.astype(np.float32)  # GV stands for Geophysical Variable\n        self.dates = dates\n        self.transform = transform\n        self.binary_mask = binary_mask\n\n    def __getitem__(self, index, return_date=True):\n        # return image and mask for a given index\n        image = self.gv[index, :, :].copy()\n        mask = self.masks[index, :, :].copy()\n        date = self.dates[index]\n\n        # transpose\n        image = image.T\n        mask = mask.T\n\n        # address regions of land that are represented as -2147483648\n        image[image < -10000] = 0\n\n        if image.ndim == 2:\n            image = np.expand_dims(image, axis=0)  # make ndim = 3\n\n        if self.transform:\n            image = self.transform(image)\n\n        # if image and mask are numpy arrays, convert them to torch tensors\n        if isinstance(image, np.ndarray):\n            image = torch.from_numpy(image)\n        if isinstance(mask, np.ndarray):\n            mask = torch.from_numpy(mask)\n\n        if self.binary_mask:\n            mask[mask >= 1] = 1\n\n        # convert to float\n        image = image.float()\n\n        if return_date:\n            # convert date to tensor\n            # date_str = date.strftime(\"%Y-%m-%d\")\n            # date =\n            return image, mask, index\n        else:\n            return image, mask\n\n    def __len__(self):\n        return self.masks.shape[0]\n\n    def plot_sample(self, N=5):\n\n        # var in first column, mask in second column\n        num_cols = 2\n        num_rows = N\n        fig, ax = plt.subplots(num_rows, num_cols, figsize=(num_cols * 4, num_rows * 4))\n        ax[0, 0].set_title(\"GV\")\n        ax[0, 1].set_title(\"Mask\")\n        for i in range(num_rows):\n            # get random sample from self\n            n = np.random.randint(0, len(self))\n            gv, mask, index = self.__getitem__(n, return_date=True)\n            gv = np.squeeze(gv.cpu().detach().numpy())\n            mask = np.squeeze(mask.cpu().detach().numpy())\n            date = self.dates[index].strftime(\"%Y-%m-%d\")\n            # ax[i, 0].pcolormesh(lon_subset, lat_subset, gv.T, cmap=\"RdBu_r\", vmin=-0.15, vmax=0.15)\n            ax[i, 0].imshow(gv, cmap=\"RdBu_r\", vmin=-0.15, vmax=0.15)\n            ax[i, 0].set_title(f\"GV ({date})\")\n            ax[i, 0].axis(\"off\")\n            ax[i, 1].imshow(mask, cmap=\"viridis\")\n            ax[i, 1].set_title(f\"Mask ({date})\")\n            ax[i, 1].axis(\"off\")\n\n    def animate(self):\n        fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n        print(f\"Drawing animation of GV and segmentation mask\")\n        artists = []\n        for i in tqdm(range(len(self)), desc=\"Animating eddies:\"):\n            gv, mask, date_idx = self.__getitem__(i, return_date=True)\n            date = self.dates[date_idx].strftime(\"%Y-%m-%d\")\n            im1 = ax[0].imshow(gv.squeeze(), cmap=\"RdBu_r\", vmin=-0.15, vmax=0.15)\n            t1 = ax[0].text(\n                0.5,\n                1.05,\n                f\"GV {date}\",\n                size=plt.rcParams[\"axes.titlesize\"],\n                ha=\"center\",\n                transform=ax[0].transAxes,\n            )\n            ax[0].axis(\"off\")\n\n            im2 = ax[1].imshow(mask.squeeze(), cmap=\"viridis\")\n            t2 = ax[1].text(\n                0.5,\n                1.05,\n                f\"Mask {date}\",\n                size=plt.rcParams[\"axes.titlesize\"],\n                ha=\"center\",\n                transform=ax[1].transAxes,\n            )\n            ax[1].axis(\"off\")\n            plt.tight_layout()\n            artists.append([im1, t1, im2, t2])\n            fig.canvas.draw()\n            fig.canvas.flush_events()\n        animation = ArtistAnimation(fig, artists, interval=500, blit=True)\n        plt.close()\n        return animation\n\ndef transform_ssh(ssh_array):\n    # normalize sea level anomaly between 0 and 1 based on min max\n    ssh_array = (ssh_array - ssh_array.min()) / (ssh_array.max() - ssh_array.min())\n    return ssh_array\n\n\n# convert npy to compressed npz\ndef convert_npy_to_npz(npy_file):\n    npz_file = npy_file.replace(\".npy\", \".npz\")\n    npy_contents = np.load(npy_file)",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "6gs3ym",
  "name" : "eddy_import",
  "description" : null,
  "code" : "# Importing the required libraries for eddy workflow\nimport os\nfrom datetime import datetime\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom py_eddy_tracker import data\nfrom py_eddy_tracker.dataset.grid import RegularGridDataset\nnum_epochs = 5",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "23nut7",
  "name" : "eddy_paths",
  "description" : null,
  "code" : "# Defining the start_axes, update_axes, plot_variabe  and setting the paths for eddy workflow\nfrom eddy_import import *\n\ndef start_axes(title):\n    fig = plt.figure(figsize=(13, 5))\n    ax = fig.add_axes([0.03, 0.03, 0.90, 0.94])\n    ax.set_aspect(\"equal\")\n    ax.set_title(title, weight=\"bold\")\n    return ax\n\n\ndef update_axes(ax, mappable=None):\n    ax.grid()\n    if mappable:\n        plt.colorbar(mappable, cax=ax.figure.add_axes([0.94, 0.05, 0.01, 0.9]))\n\n\ndef plot_variable(grid_object, var_name, ax_title, **kwargs):\n    ax = start_axes(ax_title)\n    m = grid_object.display(ax, var_name, **kwargs)\n    update_axes(ax, m)\n    ax.set_xlim(grid_object.x_c.min(), grid_object.x_c.max())\n    ax.set_ylim(grid_object.y_c.min(), grid_object.y_c.max())\n    return ax, m\n\ndata_root = os.path.join(os.path.expanduser(\"~\"), \"ML_eddies\")\ntrain_folder = os.path.join(data_root, \"cds_ssh_1998-2018_10day_interval\")\ntest_folder = os.path.join(data_root, \"cds_ssh_2019_10day_interval\")\n\nexample_file = os.path.join(test_folder, \"dt_global_twosat_phy_l4_20190101_vDT2021.nc\")\ndate = datetime(2019, 1, 1)\ng = RegularGridDataset(example_file, \"longitude\", \"latitude\")\n\nfigOutputFolder = '/Users/lakshmichetana/ML_Eddies_New_Data_Output/'\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "zr8vzj",
  "name" : "Eddy_plotvariable",
  "description" : null,
  "code" : "# setting the vmin and vmax using the eddy 'plot_variable' method\n#from eddy_paths import *\nfrom eddy_paths import figOutputFolder, plot_variable, g\nfrom copy import deepcopy\nfrom matplotlib import pyplot as plt\n\n#updated the vmin and vmax to -1 and 1\nax, m = plot_variable(\n    g,\n    \"adt\",\n    f\"ADT (m) before high-pass filter\",\n    vmin=-1,\n    vmax=1,\n)\nplt.savefig(f'{figOutputFolder}/ADT(m)_before_high-pass_filter.png', bbox_inches =\"tight\")\n#updated wavelength covered kilometers to 500 from 700\nwavelength_km = 500\n\ng_filtered = deepcopy(g)\n\ng_filtered.bessel_high_filter(\"adt\", wavelength_km)\nax, m = plot_variable(\n    g_filtered,\n    \"adt\",\n    f\"ADT (m) filtered (Final: {wavelength_km} km)\",\n    vmin=-1,\n    vmax=1,\n)\n\nplt.savefig(f'{figOutputFolder}/ADT(m)-filtered.png', bbox_inches =\"tight\")\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "4bd5xp",
  "name" : "eddy_plots",
  "description" : null,
  "code" : "# code to identify eddies, generate segmentation mask from the file and generate segmetation masks\nfrom eddy_import import *\nfrom matplotlib.path import Path\nfrom py_eddy_tracker.poly import create_vertice\nfrom copy import deepcopy\nfrom eddy_paths import *\n\n\ndef generate_segmentation_mask_from_file(\n    gridded_ssh_file,\n    date,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=0,\n    y_offset=0,\n):\n    g, g_filtered, anticyclonic, cyclonic = identify_eddies(\n        gridded_ssh_file, date, ssh_var, u_var, v_var, high_pass_wavelength_km\n    )\n    mask = generate_segmentation_mask(\n        g_filtered, anticyclonic, cyclonic, x_offset, y_offset\n    )\n    var = g.grid(ssh_var)\n    var_filtered = g_filtered.grid(ssh_var)\n    return var, var_filtered, mask\n\n\ndef identify_eddies(\n    gridded_ssh_file,\n    date,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n):\n    g = RegularGridDataset(gridded_ssh_file, \"longitude\", \"latitude\")\n    g_filtered = deepcopy(g)  # make a copy so we don't alter the original\n    g_filtered.bessel_high_filter(ssh_var, high_pass_wavelength_km)\n    anticyclonic, cyclonic = g_filtered.eddy_identification(ssh_var, u_var, v_var, date)\n    return g, g_filtered, anticyclonic, cyclonic\n\n\ndef generate_segmentation_mask(\n    grid_dataset, anticyclonic, cyclonic, x_offset, y_offset, plot=False\n):\n    \"\"\"\n    Creates a numpy array to store the segmentation mask for the grid_dataset.\n    The mask contains classes 0: no eddy, 1: anticyclonic eddy, 2: cyclonic eddy.\n    \"\"\"\n    assert (\n        cyclonic.sign_legend == \"Cyclonic\"\n        and anticyclonic.sign_legend == \"Anticyclonic\"\n    ), \"Check whether the correct order for (anti)cyclonic observations were provided.\"\n    mask = np.zeros(grid_dataset.grid(\"adt\").shape, dtype=np.uint8)\n    # cyclonic should have the same: x_name = 'contour_lon_e', y_name = 'contour_lat_e'\n    x_name, y_name = anticyclonic.intern(False)\n    for eddy in anticyclonic:\n        x_list = (eddy[x_name] - x_offset) % 360 + x_offset\n        vertices = create_vertice(x_list, eddy[y_name] + y_offset)\n        i, j = Path(vertices).pixels_in(grid_dataset)\n        mask[i, j] = 1\n\n    for eddy in cyclonic:\n        x_list = (eddy[x_name] - x_offset) % 360 + x_offset\n        y_list = eddy[y_name] + y_offset\n        i, j = Path(create_vertice(x_list, y_list)).pixels_in(grid_dataset)\n        mask[i, j] = 2\n\n    if plot:\n        ax, m = plot_variable(grid_dataset, mask, \"Segmentation Mask\", cmap=\"viridis\")\n    return mask",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "l9f2t3",
  "name" : "importing_multiprocessor",
  "description" : null,
  "code" : "#Code for generating the masks in parallel and getting dates and files\n\nfrom eddy_import import *\nfrom eddy_plots import *\nimport multiprocessing\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=1,\n    plot=False,\n    save=True,\n):\n    pool = multiprocessing.Pool(processes=20)\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    #pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    pool.close()\n    pool.join()\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "4o6voy",
  "name" : "subset_arrays",
  "description" : null,
  "code" : "#Defining the subset arrays, converting the latitude and longitude range into indices in numpy, latitude range to str and longitude range to str.\nfrom eddy_import import *\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  ",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "j4jm66",
  "name" : "train_test_subsets",
  "description" : null,
  "code" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "39ur7y",
  "name" : "InstallPackages",
  "description" : null,
  "code" : "# Dependencies Installation python code\npip install torch torchvision torchaudio matplotlib tensorboard torchmetrics seaborn opencv-python tqdm pandas\n\npip install pyEddyTracker\n",
  "lang" : "shell",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "uolls4",
  "name" : "Eddy_dependencies",
  "description" : null,
  "code" : "#eddy dependencies\ndef start_axes(title):\n    fig = plt.figure(figsize=(13, 5))\n    ax = fig.add_axes([0.03, 0.03, 0.90, 0.94])\n    ax.set_aspect(\"equal\")\n    ax.set_title(title, weight=\"bold\")\n    return ax\n\n\ndef update_axes(ax, mappable=None):\n    ax.grid()\n    if mappable:\n        plt.colorbar(mappable, cax=ax.figure.add_axes([0.94, 0.05, 0.01, 0.9]))\n\n\ndef plot_variable(grid_object, var_name, ax_title, **kwargs):\n    ax = start_axes(ax_title)\n    m = grid_object.display(ax, var_name, **kwargs)\n    update_axes(ax, m)\n    ax.set_xlim(grid_object.x_c.min(), grid_object.x_c.max())\n    ax.set_ylim(grid_object.y_c.min(), grid_object.y_c.max())\n    return ax, m",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "oc42ub",
  "name" : "data_utils",
  "description" : "python",
  "code" : "#Data utils code\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom matplotlib.animation import ArtistAnimation\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom tqdm.auto import tqdm\n\ntorch.manual_seed(42)\n\n\ndef get_eddy_dataloader(\n    files, binary=False, transform=None, batch_size=32, shuffle=True, val_split=0\n):\n    \"\"\"\n    Given a list of npz files, return dataloader(s) for train (and val).\n    Args:\n        files (list) : list of npz files\n        binary (bool) : whether to use binary masks or not.\n                        If True, treat cyclonic and anticyclonic eddies as single positive class.\n        transform (callable) : optional transform to be applied on a sample.\n        batch_size (int) : batch size for dataloader\n        shuffle (bool) : whether to shuffle the dataset or not\n        val_split (float) : fraction of data to be used as validation set.\n                            If 0, no validation split is performed.\n    Returns:\n        (train_loader, val_loader) if val_split > 0; (train_loader, None) otherwise\n    \"\"\"\n    ds, _ = get_eddy_dataset(files, binary, transform, val_split)\n    loader_kwargs = dict(batch_size=batch_size, shuffle=shuffle, pin_memory=True)\n    if val_split > 0:\n        train_ds, val_ds = ds\n        train_dl = DataLoader(train_ds, **loader_kwargs)\n        val_dl = DataLoader(val_ds, **loader_kwargs)\n    else:\n        train_dl = DataLoader(ds, **loader_kwargs)\n        val_dl = None\n    return train_dl, val_dl\n\n\ndef get_eddy_dataset(files, binary=None, transform=None, val_split=0):\n    masks, dates, _, var_filtered, lon, lat, npz_dict = read_npz_files(files)\n    print(f\"Read {len(masks)} samples from {files}.\")\n    if val_split > 0:\n        # split into training and validation sets (80% training, 20% validation)\n        train_idx, val_idx = train_test_split(\n            np.arange(len(masks)), test_size=val_split, random_state=42\n        )\n        train_ds = EddyDataset(\n            masks[train_idx],\n            var_filtered[train_idx],\n            dates[train_idx],\n            transform=transform,\n            binary_mask=binary,\n        )\n\n        val_ds = EddyDataset(\n            masks[val_idx],\n            var_filtered[val_idx],\n            dates[val_idx],\n            transform=transform,\n            binary_mask=binary,\n        )\n    else:\n        train_ds = EddyDataset(\n            masks, var_filtered, dates, transform=transform, binary_mask=binary\n        )\n        val_ds = None\n    return train_ds, val_ds\n\n\ndef read_npz_files(npz_files: list):\n    \"\"\"Load a list of npz files, concatenate, and return separate arrays for eddy segmentation\"\"\"\n    # load npz file into separate variables\n    if isinstance(npz_files, str):\n        npz_files = [npz_files]\n    npz_contents = [np.load(file, allow_pickle=True) for file in npz_files]\n    masks, dates, var, var_filtered, lon_subset, lat_subset = eddy_dict_to_vars(\n        npz_contents\n    )\n    return masks, dates, var, var_filtered, lon_subset, lat_subset, npz_contents\n\n\ndef eddy_dict_to_vars(npz_contents):\n    masks = np.concatenate(\n        [npz_content[\"masks\"] for npz_content in npz_contents], axis=0\n    )\n    dates = np.concatenate(\n        [npz_content[\"dates\"] for npz_content in npz_contents], axis=0\n    )\n    # var = np.concatenate([npz_content[\"var\"] for npz_content in npz_contents], axis=0)\n    var = None\n    var_filtered = np.concatenate(\n        [npz_content[\"var_filtered\"] for npz_content in npz_contents], axis=0\n    )\n    if \"lon_subset\" in npz_contents[0]:\n        lon_subset = np.concatenate(\n            [npz_content[\"lon_subset\"] for npz_content in npz_contents], axis=0\n        )\n        lat_subset = np.concatenate(\n            [npz_content[\"lat_subset\"] for npz_content in npz_contents], axis=0\n        )\n    else:\n        lon_subset = lat_subset = None\n    return masks, dates, var, var_filtered, lon_subset, lat_subset\n\n\nclass EddyDataset(torch.utils.data.Dataset):\n    def __init__(self, masks, gv, dates, transform=None, binary_mask=False):\n        \"\"\"PyTorch dataset for eddy detection\n        Args:\n            masks (np.array): array of segmentation masks with shape: (N_dates, N_lon, N_lat)\n                Can have 3 values: 0, 1 and 2, where 1 = anticyclonic, 2 = cyclonic and 0 = no eddy\n            gv (np.array): array of GV maps with shape: (N_dates, N_lon, N_lat)\n                Example GVs: sea level anomaly, absolute dynamic topography\n            transform (callable, optional): Transformation to be applied on a sample.\n            binary_mask (bool, optional): If true, all eddies (anticyclonic and cyclonic) will be assigned a value of 1\n        \"\"\"\n        self.masks = masks\n        self.gv = gv.astype(np.float32)  # GV stands for Geophysical Variable\n        self.dates = dates\n        self.transform = transform\n        self.binary_mask = binary_mask\n\n    def __getitem__(self, index, return_date=True):\n        # return image and mask for a given index\n        image = self.gv[index, :, :].copy()\n        mask = self.masks[index, :, :].copy()\n        date = self.dates[index]\n\n        # transpose\n        image = image.T\n        mask = mask.T\n\n        # address regions of land that are represented as -2147483648\n        image[image < -10000] = 0\n\n        if image.ndim == 2:\n            image = np.expand_dims(image, axis=0)  # make ndim = 3\n\n        if self.transform:\n            image = self.transform(image)\n\n        # if image and mask are numpy arrays, convert them to torch tensors\n        if isinstance(image, np.ndarray):\n            image = torch.from_numpy(image)\n        if isinstance(mask, np.ndarray):\n            mask = torch.from_numpy(mask)\n\n        if self.binary_mask:\n            mask[mask >= 1] = 1\n\n        # convert to float\n        image = image.float()\n\n        if return_date:\n            # convert date to tensor\n            # date_str = date.strftime(\"%Y-%m-%d\")\n            # date =\n            return image, mask, index\n        else:\n            return image, mask\n\n    def __len__(self):\n        return self.masks.shape[0]\n\n    def plot_sample(self, N=5):\n\n        # var in first column, mask in second column\n        num_cols = 2\n        num_rows = N\n        fig, ax = plt.subplots(num_rows, num_cols, figsize=(num_cols * 4, num_rows * 4))\n        ax[0, 0].set_title(\"GV\")\n        ax[0, 1].set_title(\"Mask\")\n        for i in range(num_rows):\n            # get random sample from self\n            n = np.random.randint(0, len(self))\n            gv, mask, index = self.__getitem__(n, return_date=True)\n            gv = np.squeeze(gv.cpu().detach().numpy())\n            mask = np.squeeze(mask.cpu().detach().numpy())\n            date = self.dates[index].strftime(\"%Y-%m-%d\")\n            # ax[i, 0].pcolormesh(lon_subset, lat_subset, gv.T, cmap=\"RdBu_r\", vmin=-0.15, vmax=0.15)\n            ax[i, 0].imshow(gv, cmap=\"RdBu_r\", vmin=-0.15, vmax=0.15)\n            ax[i, 0].set_title(f\"GV ({date})\")\n            ax[i, 0].axis(\"off\")\n            ax[i, 1].imshow(mask, cmap=\"viridis\")\n            ax[i, 1].set_title(f\"Mask ({date})\")\n            ax[i, 1].axis(\"off\")\n\n    def animate(self):\n        fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n        print(f\"Drawing animation of GV and segmentation mask\")\n        artists = []\n        for i in tqdm(range(len(self)), desc=\"Animating eddies:\"):\n            gv, mask, date_idx = self.__getitem__(i, return_date=True)\n            date = self.dates[date_idx].strftime(\"%Y-%m-%d\")\n            im1 = ax[0].imshow(gv.squeeze(), cmap=\"RdBu_r\", vmin=-0.15, vmax=0.15)\n            t1 = ax[0].text(\n                0.5,\n                1.05,\n                f\"GV {date}\",\n                size=plt.rcParams[\"axes.titlesize\"],\n                ha=\"center\",\n                transform=ax[0].transAxes,\n            )\n            ax[0].axis(\"off\")\n\n            im2 = ax[1].imshow(mask.squeeze(), cmap=\"viridis\")\n            t2 = ax[1].text(\n                0.5,\n                1.05,\n                f\"Mask {date}\",\n                size=plt.rcParams[\"axes.titlesize\"],\n                ha=\"center\",\n                transform=ax[1].transAxes,\n            )\n            ax[1].axis(\"off\")\n            plt.tight_layout()\n            artists.append([im1, t1, im2, t2])\n            fig.canvas.draw()\n            fig.canvas.flush_events()\n        animation = ArtistAnimation(fig, artists, interval=500, blit=True)\n        plt.close()\n        return animation\n\ndef transform_ssh(ssh_array):\n    # normalize sea level anomaly between 0 and 1 based on min max\n    ssh_array = (ssh_array - ssh_array.min()) / (ssh_array.max() - ssh_array.min())\n    return ssh_array\n\n\n# convert npy to compressed npz\ndef convert_npy_to_npz(npy_file):\n    npz_file = npy_file.replace(\".npy\", \".npz\")\n    npy_contents = np.load(npy_file)",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "bzgeyy",
  "name" : "eddynet",
  "description" : null,
  "code" : "#Eddynet\nimport collections\nfrom itertools import repeat\nfrom typing import OrderedDict\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass EddyNet(nn.Module):\n    \"\"\"\n    PyTorch implementation of EddyNet from Lguensat et al. (2018)\n    Original implementation in TensorFlow: https://github.com/redouanelg/EddyNet\n    \"\"\"\n    def __init__(self, num_classes, num_filters, kernel_size):\n        super(EddyNet, self).__init__()\n        # encoder\n        self.encoder1 = EddyNet._block(1, num_filters, kernel_size, \"enc1\", dropout=0.2)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder2 = EddyNet._block(\n            num_filters, num_filters, kernel_size, \"enc2\", dropout=0.3\n        )\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder3 = EddyNet._block(\n            num_filters, num_filters, kernel_size, \"enc3\", dropout=0.4\n        )\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.encoder4 = EddyNet._block(\n            num_filters, num_filters, kernel_size, \"enc4\", dropout=0.5\n        )\n\n        # decoder\n        self.decoder3 = EddyNet.decoder_block(\n            num_filters * 2, num_filters, kernel_size, \"dec3\", dropout=0.4\n        )\n        self.decoder2 = EddyNet.decoder_block(\n            num_filters * 2, num_filters, kernel_size, \"dec2\", dropout=0.3\n        )\n        self.decoder1 = EddyNet.decoder_block(\n            num_filters * 2, num_filters, kernel_size, \"dec1\", dropout=0.2\n        )\n\n        # final layer\n        self.final_conv = nn.Conv2d(\n            num_filters, num_classes, kernel_size=1, padding=0, bias=False\n        )\n\n    @staticmethod\n    def conv_block(in_channels, out_channels, kernel_size, name, num, dropout=0):\n        layers = {\n            f\"{name}_conv{num}\": Conv2dSame(in_channels, out_channels, kernel_size),\n            f\"{name}_bn{num}\": nn.BatchNorm2d(out_channels),\n            f\"{name}_relu{num}\": nn.ReLU(inplace=True),\n        }\n        if dropout > 0:\n            layers[f\"{name}_dropout\"] = nn.Dropout(p=dropout)\n\n        return nn.Sequential(OrderedDict(layers))\n\n    @staticmethod\n    def _block(in_channels, out_channels, kernel_size, name, dropout=0):\n        conv1 = EddyNet.conv_block(in_channels, out_channels, kernel_size, name, 1)\n        conv2 = EddyNet.conv_block(\n            out_channels, out_channels, kernel_size, name, 2, dropout=dropout\n        )\n        return nn.Sequential(conv1, conv2)\n\n    @staticmethod\n    def decoder_block(in_channels, out_channels, kernel_size, name, dropout=0):\n        return EddyNet._block(in_channels, out_channels, kernel_size, name, dropout)\n\n    def forward(self, x):\n        # encoder\n        enc1 = self.encoder1(x)\n        pool1 = self.pool1(enc1)\n\n        enc2 = self.encoder2(pool1)\n        pool2 = self.pool2(enc2)\n\n        enc3 = self.encoder3(pool2)\n        pool3 = self.pool3(enc3)\n\n        # bottleneck?\n        enc4 = self.encoder4(pool3)\n\n        # decoder\n        dec3 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)(enc4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.decoder3(dec3)\n\n        dec2 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.decoder2(dec2)\n\n        dec1 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.decoder1(dec1)\n\n        # final layer\n        final = self.final_conv(dec1)\n\n        # softmax\n        final = nn.Softmax(dim=1)(final)\n\n        return final\n\n\nclass Conv2dSame(nn.Module):\n    \"\"\"Manual convolution with same padding\n    https://discuss.pytorch.org/t/same-padding-equivalent-in-pytorch/85121/9\n    Although PyTorch >= 1.10.0 supports ``padding='same'`` as a keyword\n    argument, this does not export to CoreML as of coremltools 5.1.0,\n    so we need to implement the internal torch logic manually.\n    Currently the ``RuntimeError`` is\n    \"PyTorch convert function for op '_convolution_mode' not implemented\"\n    \"\"\"\n\n    def __init__(\n        self, in_channels, out_channels, kernel_size, stride=1, dilation=1, **kwargs\n    ):\n        \"\"\"Wrap base convolution layer\n        See official PyTorch documentation for parameter details\n        https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n        \"\"\"\n        super().__init__()\n        self.conv = nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            dilation=dilation,\n            **kwargs,\n        )\n\n        # Setup internal representations\n        kernel_size_ = _pair(kernel_size)\n        dilation_ = _pair(dilation)\n        self._reversed_padding_repeated_twice = [0, 0] * len(kernel_size_)\n\n        # Follow the logic from ``nn/modules/conv.py:_ConvNd``\n        for d, k, i in zip(\n            dilation_, kernel_size_, range(len(kernel_size_) - 1, -1, -1)\n        ):\n            total_padding = d * (k - 1)\n            left_pad = total_padding // 2\n            self._reversed_padding_repeated_twice[2 * i] = left_pad\n            self._reversed_padding_repeated_twice[2 * i + 1] = total_padding - left_pad\n\n    def forward(self, imgs):\n        \"\"\"Setup padding so same spatial dimensions are returned\n        All shapes (input/output) are ``(N, C, W, H)`` convention\n        :param torch.Tensor imgs:\n        :return torch.Tensor:\n        \"\"\"\n        padded = F.pad(imgs, self._reversed_padding_repeated_twice)\n        return self.conv(padded)\n\n\ndef _ntuple(n):\n    \"\"\"Copy from PyTorch since internal function is not importable\n    See ``nn/modules/utils.py:6``\n    \"\"\"\n\n    def parse(x):\n        if isinstance(x, collections.abc.Iterable):\n            return tuple(x)\n        return tuple(repeat(x, n))\n\n    return parse\n\n\n_pair = _ntuple(2)",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "bomi2j",
  "name" : "eddy_train_utils",
  "description" : "python",
  "code" : "#Eddy Train Utils\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "uji5d1",
  "name" : "generateMasks_TrainTestPlots",
  "description" : null,
  "code" : "#getting the test dates and files of training sets from 1998 - 2018 and from training set 2019 and also setting the logging level as ERROR\nfrom eddy_import import *\nfrom importing_multiprocessor import *\nfrom eddy_paths import *\nfrom eddy_plots import *\nimport logging\nfrom subset_arrays import *\n#from Generate_Masks import *\n# northern pacific (32x32 degree -> 128x128 pixels)\n\ndef funcGenerateMasks():\n  logging.getLogger(\"pet\").setLevel(logging.ERROR)\n\n    # enter the AVISO filename pattern\n    # year, month, and day in file_pattern will be filled in get_dates_and_files:\n  file_pattern = \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n  # training set: 1998 - 2018\n  train_dates, train_files = get_dates_and_files(\n      range(2000, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n  )\n  train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n      train_files, train_dates\n  )\n\n\n# test set: 2019\n  test_dates, test_files = get_dates_and_files(\n      [2019], range(1, 13), [1, 10, 20, 30], test_folder, file_pattern\n  )\n  test_adt, test_adt_filtered, test_masks = generate_masks_in_parallel(\n      test_files, test_dates\n  )\n\n\n  lon_range = (-166, -134)\n  lat_range = (14, 46)\n\n  train_subset = subset_arrays(\n      train_masks,\n      train_adt,\n      train_adt_filtered,\n      train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n  )\n\n  test_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n  )\n\n  plt.savefig(f'{figOutputFolder}/Train_Test_Subset_Img.png', bbox_inches =\"tight\")\n\nif __name__ == \"__main__\":\n  funcGenerateMasks()\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "qsxf3a",
  "name" : "EddyDataLoader_PixelTraining_TrainingDataset_&_Pytorch",
  "description" : null,
  "code" : "from file_paths import *\nfrom declaring_epochs_size import *\nfrom data_utils import get_eddy_dataloader\nfrom eddy_import import *\nimport numpy as np\nimport torch\nfrom get_eddy_dataloader import *\nfrom eddynet import EddyNet\nfrom eddy_paths import figOutputFolder\n\n# set binary = false if we want to distinguish between cyclonic and anticyclonic\nbinary = False\nnum_classes = 2 if binary else 3\ntrain_loader, _ = get_eddy_dataloader(train_file, binary=binary, batch_size=batch_size)\nval_loader, _ = get_eddy_dataloader(\n    val_file, binary=binary, batch_size=batch_size, shuffle=False\n)\n\n#Looking at the distribution of class frequencies to identify class imbalances\ntrain_masks = train_loader.dataset.masks.copy()\nclass_frequency = np.bincount(train_masks.flatten())\ntotal_pixels = sum(class_frequency)\nprint(\n    f\"Total number of pixels in training set: {total_pixels/1e6:.2f} megapixels\"\n    f\" across {len(train_masks)} SSH maps\\n\"\n    f\"Number of pixels that are not eddies: {class_frequency[0]/1e6:.2f} megapixels \"\n    f\"({class_frequency[0]/total_pixels * 100:.2f}%)\\n\"\n    f\"Number of pixels that are anticyclonic eddies: {class_frequency[1]/1e6:.2f} megapixels \"\n    f\"({class_frequency[1]/total_pixels * 100:.2f}%)\\n\"\n    f\"Number of pixels that are cyclonic eddies: {class_frequency[2]/1e6:.2f} megapixels \"\n    f\"({class_frequency[2]/total_pixels * 100:.2f}%)\\n\"\n)\n\n#Using plot_sample to visualize the dataset we just loaded.\ntrain_loader.dataset.plot_sample(N=3)\nplt.savefig(f\"{figOutputFolder}/datasetPlots\",bbox=\"tight\")\n\n#Segmentation Model:\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available(): \n    model.to(device=\"cuda\")",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "tldnzh",
  "name" : "LossFunction_LearningRate_MetricsEvaluation",
  "description" : null,
  "code" : "#import os\n#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n\n#loss function\nprint('start imports')\n\nimport torch\nprint('torch')\n\nfrom eddy_import import *\nprint('eddy_import')\n\nfrom pytorch_local import *\nprint('pytorch_local')\n\nfrom data_utils import *\nprint('get_eddy_dataloader')\n\nimport torchmetrics\nprint('torchmetrics')\n\nimport datetime\nprint('datetime')\n\nfrom torch.utils.tensorboard import SummaryWriter\nprint('SummaryWriter')\n\nimport cv2  # use cv2 to count eddies by drawing contours around segmentation masks\nprint('cv2')\n\nimport matplotlib.pyplot as plt\nprint('matplotlib.pyplot')\n#import numpy as np\n\nfrom tqdm.auto import tqdm\nprint('tqdm.auto ')\n\nfrom eddy_train_utils import run_batch, write_metrics_to_tensorboard, filter_scalar_metrics, EarlyStopping\nprint('end of imports')\n\n#Run the training loop for prescribed num_epochs\nfrom declaring_epochs_size import *\nfrom eddy_train_utils import add_hparams\n\ndef get_metrics(N, sync=False):\n  \"\"\"Get the metrics to be used in the training loop.\n      Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n          train_metrics (MetricCollection): The metrics to be used in the training loop.\n          val_metrics (MetricCollection): The metrics to be used in validation.\n  \"\"\"\n      # Define metrics and move to GPU if available\n  metrics = [\n    torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n    torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n#           torchmetrics.F1Score(  # TODO: Homework: verify in tensorboard that this is equivalent to accuracy\n#               average=\"micro\",\n#               dist_sync_on_step=sync,\n#               num_classes=N,\n#           ),\n        torchmetrics.F1Score(\n            average=\"none\",  # return F1 for each class\n            dist_sync_on_step=sync,\n            num_classes=N,\n        )\n  ]\n  if torch.cuda.is_available():  # move metrics to the same device as model\n      [metric.to(\"cuda\") for metric in metrics]\n\n  train_metrics = torchmetrics.MetricCollection(metrics)\n  val_metrics = train_metrics.clone()\n  return train_metrics, val_metrics\n\ndef run_epoch(\n      epoch,\n      model,\n      loss_fn,\n      optimizer,\n      scheduler,\n      train_loader,\n      val_loader,\n      train_metrics,\n      val_metrics,\n      writer,\n  ):\n      leave = epoch == num_epochs - 1  # leave progress bar on screen after last epoch\n\n      model.train()\n      # training set\n      for batch_num, (gvs, seg_masks, date_indices) in enumerate(train_loader):\n          train_loss = run_batch(\n              model, loss_fn, gvs, seg_masks, optimizer, scheduler, train_metrics\n          )\n          iter_num = epoch * len(train_loader) + batch_num\n          writer.add_scalar(\"train/lr\", scheduler.get_last_lr()[-1], iter_num)\n\n      # validation set\n      images, preds, labels, dates = [], [], [], []\n      model.eval()\n      with torch.no_grad():\n          val_loss = num_examples = 0\n          for gvs, masks, date_indices in val_loader:\n              # continue\n              loss_, pred_batch = run_batch(\n                  model, loss_fn, gvs, masks, metrics=val_metrics, return_pred=True\n              )\n              val_loss += loss_\n              num_examples += np.prod(gvs.shape)\n              # keep track of images, preds, labels for plotting\n              images.append(gvs)\n              preds.append(pred_batch)\n              labels.append(masks)\n              dates.append(date_indices)\n\n      # calculate average validation loss across all samples\n      # num_examples should be equal to sum of all pixels\n      val_loss = val_loss / num_examples\n\n      # plot validation images and log to tensorboard\n      ## move images, preds, labels, dates to cpu\n      images = torch.cat(images).cpu().numpy()\n      labels = torch.cat(labels).cpu().numpy()\n      preds = torch.cat(preds).cpu().numpy()\n      dates = torch.cat(dates).cpu().numpy()\n      ## convert indices to actual dates\n      dates = [val_loader.dataset.dates[i].strftime(\"%Y-%m-%d\") for i in dates]\n\n      # take random images from validation set\n      if epoch == 0:\n          indices_ = np.random.choice(\n              len(images), num_plots_in_tensorboard, replace=False\n          )\n          for i, idx in enumerate(indices_):\n              random_plot_indices[i] = idx\n      fig, ax = plt.subplots(num_plots_in_tensorboard, 3, figsize=(20, 30))\n      for n, i in enumerate(random_plot_indices):\n          date, img, mask, pred = dates[i], images[i], labels[i], preds[i]\n          artists = plot_eddies_on_axes(\n              date, img, mask, pred, ax[n, 0], ax[n, 1], ax[n, 2]\n          )\n      plt.tight_layout()\n      writer.add_figure(f\"val/sample_prediction\", fig, global_step=epoch)\n\n      # Update tensorboard\n      train_m = write_metrics_to_tensorboard(\n          num_classes, train_metrics, writer, epoch, \"train\"\n      )\n      val_m = write_metrics_to_tensorboard(num_classes, val_metrics, writer, epoch, \"val\")\n\n      writer.add_scalar(\"train/loss\", train_loss, epoch)\n      writer.add_scalar(\"val/loss\", val_loss, epoch)\n\n      # reset metrics after each epoch\n      train_metrics.reset()\n      val_metrics.reset()\n\n      train_m = filter_scalar_metrics(train_m)\n      val_m = filter_scalar_metrics(val_m)\n\n      return train_loss, val_loss, train_m, val_m\n      print('after run_epoch')\n\ndef plot_eddies_on_axes(date, img, mask, pred, a1, a2, a3):\n    im1 = a1.imshow(img.squeeze(), cmap=\"viridis\")\n\n      # blit canvas for a1 a2 a3\n    a1.figure.canvas.draw()\n    a1.figure.canvas.flush_events()\n    a2.figure.canvas.draw()\n    a2.figure.canvas.flush_events()\n    a3.figure.canvas.draw()\n    a3.figure.canvas.flush_events()\n\n      # https://stackoverflow.com/a/49159236\n    t1 = a1.text(\n        0.5,\n        1.05,\n        f\"ADT {date}\",\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a1.transAxes,\n    )\n      # set axis off\n    a1.axis(\"off\")\n\n      # count number of eddies in mask and pred\n    mask_anticyclonic = count_eddies(mask, \"anticyclonic\")\n    mask_cyclonic = count_eddies(mask, \"cyclonic\")\n    pred_anticyclonic = count_eddies(pred, \"anticyclonic\")\n    pred_cyclonic = count_eddies(pred, \"cyclonic\")\n\n      # calculate accuracy between pred and mask\n    acc = np.sum(pred == mask) / mask.size\n    im2 = a2.imshow(pred, cmap=\"viridis\")\n    t2 = a2.text(\n        0.5,\n        1.05,\n        (\n            f\"Prediction (Acc = {acc:.3f} |\"\n            f\" Num. anticyclonic = {pred_anticyclonic} |\"\n            f\" Num. cyclonic = {pred_cyclonic})\"\n        ),\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a2.transAxes,\n    )\n    a2.axis(\"off\")\n    im3 = a3.imshow(mask, cmap=\"viridis\")\n    t3 = a3.text(\n        0.5,\n        1.05,\n        (\n            f\"Ground Truth\"\n            f\" (Num. anticyclonic: {mask_anticyclonic} |\"\n            f\" Num. cyclonic: {mask_cyclonic})\"\n        ),\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a3.transAxes,\n    )\n    a3.axis(\"off\")\n\n    return im1, t1, im2, t2, im3, t3\n\n\ndef count_eddies(arr, eddy_type=\"both\"):\n    mask = np.zeros(arr.shape, dtype=np.uint8)\n    if eddy_type == \"anticyclonic\":\n        mask[arr == 1] = 1\n    elif eddy_type == \"cyclonic\":\n        mask[arr == 2] = 1\n    else:\n        mask[arr > 0] = 1\n    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    return len(contours)\n\n\ndef mainFunction():\n  print('Before Loss Function')\n  loss_fn = torch.nn.CrossEntropyLoss()\n  print('After loss Function')\n  # TODO (homework): Try \n  # loss_fn =    torch.nn.CrossEntropyLoss(weight=torch.Tensor(total_pixels/class_frequency))\n\n  # learning rate for use in OneCycle scheduler\n  initial_lr = 1e-6\n  max_lr = 5e-4\n  num_epochs = 1\n\n  print('Before scheduler initiation')\n  optimizer = torch.optim.Adam(model.parameters(), lr=max_lr)\n  scheduler = torch.optim.lr_scheduler.OneCycleLR(\n      optimizer,\n      max_lr=max_lr,\n      steps_per_epoch=len(train_loader),\n      epochs=num_epochs,\n      div_factor=max_lr / initial_lr,\n      pct_start=0.3,\n  )\n  print('after scheduler initiation')\n\n  #Defining and using the get_metrics function\n\n  train_metrics, val_metrics = get_metrics(num_classes)\n\n\n#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\n  import datetime\n  #print('before tensorboard dir')\n  '''tensorboard_dir = os.path.join(\n      os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n      \"tensorboard\",\n      # add current timestamp\n      f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n  )\n  writer = SummaryWriter(log_dir=tensorboard_dir)\n  print(\n      f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n      f\"Writing Tensorboard logs to {writer.log_dir}\"\n      f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n  )\n  print('after tensorboard dir')'''\n\n  #Train the model: Defining training loop\n\n  num_plots_in_tensorboard = 5\n  # will populate this later with random numbers:\n  random_plot_indices = np.zeros((num_plots_in_tensorboard,), np.uint8)\n\n  print('before run_epoch')\n  \n# create some aliases\n  loss, opt, sched = loss_fn, optimizer, scheduler\n  num_epochs = 5\n\n  #checkpoint_path = os.path.join(tensorboard_dir, \"model_ckpt_{epoch}.pt\")\n  '''early_stopping = EarlyStopping(\n      patience=10,\n     # path=checkpoint_path,\n      min_epochs=30,\n  )'''\n\n  progress_bar = tqdm(range(num_epochs), desc=\"Training: \", unit=\"epoch(s)\")\n  for N in progress_bar:\n      train_loss, val_loss, train_m, val_m = run_epoch(\n          N,\n          model,\n          loss,\n          opt,\n          sched,\n          train_loader,\n          val_loader,\n          train_metrics,\n          val_metrics,\n         # writer,\n      )\n\n      # update progress bar\n      train_m_copy = {f\"train_{k}\".lower(): v.cpu().numpy() for k, v in train_m.items()}\n      val_m_copy = {f\"val_{k}\".lower(): v.cpu().numpy() for k, v in val_m.items()}\n      progress_bar.set_postfix(**train_m_copy, **val_m_copy)\n\n      # early stopping when validation loss stops improving\n      early_stopping.path = checkpoint_path.format(epoch=N)\n      early_stopping(val_loss, model)\n      if early_stopping.early_stop:\n          print(\n              f\"Early stopping at epoch {N}\"\n              f\" with validation loss {val_loss:.3f}\"\n              f\" and training loss {train_loss:.3f}\"\n          )\n          break\n\n      # TODO (homework): save checkpoint every 10 epochs\n\n  # add hyperparameters and corresponding results to tensorboard HParams table\n  hparam_dict = {\n      \"backbone\": model_name,\n      \"num_epochs\": num_epochs,\n      \"batch_size\": batch_size,\n      \"num_classes\": num_classes,\n      \"binary_mask\": binary,\n      \"optimizer\": optimizer.__class__.__name__,\n      \"max_lr\": max_lr,\n      \"loss_function\": loss_fn.__class__.__name__,\n  }\n  metrics_dict = {\n      \"train/end_epoch\": N,\n      \"train/loss\": train_loss,\n      \"train/Accuracy\": train_m[\"Accuracy\"],\n      \"val/loss\": val_loss,\n      \"val/Accuracy\": val_m[\"Accuracy\"],\n  }\n  add_hparams(writer, hparam_dict, metrics_dict, epoch_num=N)\n  writer.close()\n\n  print('model path setting')\n  # save model to tensorboard folder\n  model_path = os.path.join(tensorboard_dir, f\"model_ckpt_{N+1}.pt\")\n  print('entering save option')\n  torch.save(model.state_dict(), model_path)\n\n  \n  \nif __name__ == \"__main__\":\n  mainFunction()\n  \n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "k3gm1y",
  "name" : "New_Eddy_Plotvariable",
  "description" : null,
  "code" : "# setting the vmin and vmax using the eddy 'plot_variable' method\nfrom eddy_paths import *\nfrom copy import deepcopy\nfrom matplotlib import pyplot as plt\n\n#updated the vmin and vmax to -1 and 1\nax, m = plot_variable(\n    g,\n    \"adt\",\n    f\"ADT (m) before high-pass filter\",\n    vmin=-5,\n    vmax=5,\n)\nplt.savefig(f'{figOutputFolder}/ADT(m)_before_high-pass_filter_with_updatedVminVmax&Wavelength_KM.png', bbox_inches =\"tight\")\n#updated wavelength covered kilometers to 100 from 700\nwavelength_km = 100\n\ng_filtered = deepcopy(g)\n\ng_filtered.bessel_high_filter(\"adt\", wavelength_km)\nax, m = plot_variable(\n    g_filtered,\n    \"adt\",\n    f\"ADT (m) filtered (Final: {wavelength_km} km)\",\n    vmin=-5,\n    vmax=5,\n)\n\nplt.savefig(f'{figOutputFolder}/ADT(m)-filtered_with_updatedVminVmax&Wavelength_KM.png', bbox_inches =\"tight\")\n",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "2if9sm",
  "name" : "Add_Segmentation_Plots",
  "description" : null,
  "code" : "#code for plotting segmentation masks, antcyclonic display, cyclonic display and updating the axis\nfrom eddy_plots import *\nfrom eddy_paths import *\nfrom copy import deepcopy\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Detected Eddies on ADT (m).png', bbox_inches =\"tight\")\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Segmentation Mask.png', bbox_inches =\"tight\")",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
},{
  "id" : "xm5gfq",
  "name" : "New_Add_Segmentation_Plots",
  "description" : null,
  "code" : "#code for plotting segmentation masks, antcyclonic display, cyclonic display and updating the axis\nfrom eddy_plots import *\nfrom eddy_paths import *\nfrom copy import deepcopy\n\n#updated the r4ef details and also the vmin and vmax values\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-5, vmax=5, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-250\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-250\n)\nax.legend()\nupdate_axes(ax)\n\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Detected Eddies on ADT (m)_with_UpdatedVminVmax&RefValues.png', bbox_inches =\"tight\")\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)\nplt.savefig(f'{figOutputFolder}/Segmentation Mask_with_UpdatedVminVmax&RefValues.png', bbox_inches =\"tight\")",
  "lang" : "python",
  "owner" : "111111",
  "confidential" : "FALSE"
}]
